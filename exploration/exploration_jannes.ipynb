{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "colonial-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './../')\n",
    "import numpy as np\n",
    "import bbdc2021\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "reload(bbdc2021)\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "impaired-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, labelList, timepoints = bbdc2021.read_train(\"./../data/dataset_fft\")\n",
    "X_train_cropped = [np.delete(x,1,0) for x in X_train_orig]\n",
    "Y_train_cropped = [np.delete(x,1,0) for x in Y_train_orig]\n",
    "X_train, Y_train, X_validation, Y_validation, X_test, Y_test = bbdc2021.splitTrain(X_train_cropped, Y_train_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secure-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 16)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 208, 16)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 208, 32)      1568        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 208, 32)      128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 208, 32)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 208, 32)      3104        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 208, 32)      128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 208, 32)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 104, 32)      0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 104, 64)      6208        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 104, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 104, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 104, 64)      12352       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 104, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 104, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 52, 64)       0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 52, 128)      24704       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 128)      512         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 52, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 52, 128)      49280       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 52, 128)      512         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 52, 128)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 104, 128)     0           re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 104, 192)     0           up_sampling1d_1[0][0]            \n",
      "                                                                 re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 104, 64)      36928       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 104, 64)      256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 104, 64)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 104, 64)      12352       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 104, 64)      256         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 104, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 208, 64)      0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 208, 96)      0           up_sampling1d_2[0][0]            \n",
      "                                                                 re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 208, 32)      9248        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 208, 32)      128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 208, 32)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 208, 32)      3104        re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 208, 32)      128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 208, 32)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 208, 13)      429         re_lu_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 161,837\n",
      "Trainable params: 160,557\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "channels = [32, 64, 128]\n",
    "inputShape = X_train[0].shape\n",
    "print(inputShape)\n",
    "\n",
    "#input_layer = layers.Input(shape=(296,296,1))\n",
    "input_layer = layers.Input(shape=(inputShape))\n",
    "##############################\n",
    "x = input_layer\n",
    "# Encoder Start\n",
    "x = layers.Conv1D(channels[0], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv1D(channels[0], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "sh1 = layers.ReLU()(x)\n",
    "\n",
    "x = layers.MaxPooling1D()(sh1)\n",
    "#############################\n",
    "x = layers.Conv1D(channels[1], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv1D(channels[1], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "sh2 = layers.ReLU()(x)\n",
    "x = layers.MaxPooling1D()(sh2)\n",
    "#############################\n",
    "x = layers.Conv1D(channels[2], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv1D(channels[2], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "#Decoder start\n",
    "x = layers.UpSampling1D(2)(x)\n",
    "\n",
    "############################\n",
    "#sh2 = layers.Cropping1D(cropping=10)(sh2)\n",
    "x = layers.Concatenate()([x,sh2])\n",
    "x = layers.Conv1D(channels[1], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv1D(channels[1], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.UpSampling1D(2)(x)\n",
    "#############################\n",
    "#sh1 = layers.Cropping1D(cropping=16)(sh1)\n",
    "x = layers.Concatenate()([x,sh1])\n",
    "x = layers.Conv1D(channels[0], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv1D(channels[0], kernel_size=3, padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv1D(13, kernel_size=1, activation=\"softmax\", padding='same')(x)\n",
    "\n",
    "model = keras.models.Model(inputs=input_layer, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-practice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "8000/8000 [==============================] - 72s 9ms/step - loss: 0.2257 - mae: 0.0136 - val_loss: 0.9747 - val_mae: 0.0494\n",
      "Epoch 2/15\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.2077 - mae: 0.0137 - val_loss: 1.5624 - val_mae: 0.0667\n",
      "Epoch 3/15\n",
      "7815/8000 [============================>.] - ETA: 2s - loss: 0.2011 - mae: 0.0135"
     ]
    }
   ],
   "source": [
    "#Mit crossentropy\n",
    "model = keras.models.Model(inputs=input_layer, outputs=x)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mae'])\n",
    "history = model.fit(np.array(X_train),np.array(Y_train), batch_size=15, epochs=15, validation_data=(np.array(X_validation), np.array(Y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sitting-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.1780 - mae: 0.0629 - val_loss: 0.2708 - val_mae: 0.0806\n",
      "Epoch 2/15\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.1234 - mae: 0.0425 - val_loss: 0.3198 - val_mae: 0.0970\n",
      "Epoch 3/15\n",
      "8000/8000 [==============================] - 52s 7ms/step - loss: 0.1043 - mae: 0.0356 - val_loss: 0.3833 - val_mae: 0.1051\n",
      "Epoch 4/15\n",
      "8000/8000 [==============================] - 55s 7ms/step - loss: 0.0928 - mae: 0.0315 - val_loss: 0.2020 - val_mae: 0.0628\n",
      "Epoch 5/15\n",
      "8000/8000 [==============================] - 55s 7ms/step - loss: 0.0847 - mae: 0.0287 - val_loss: 0.1799 - val_mae: 0.0583\n",
      "Epoch 6/15\n",
      "8000/8000 [==============================] - 55s 7ms/step - loss: 0.0790 - mae: 0.0268 - val_loss: 0.1970 - val_mae: 0.0585\n",
      "Epoch 7/15\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.0740 - mae: 0.0250 - val_loss: 0.2961 - val_mae: 0.0865\n",
      "Epoch 8/15\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.0705 - mae: 0.0238 - val_loss: 0.1588 - val_mae: 0.0484\n",
      "Epoch 9/15\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0662 - mae: 0.0223 - val_loss: 0.2298 - val_mae: 0.0693\n",
      "Epoch 10/15\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.0632 - mae: 0.0214 - val_loss: 0.1829 - val_mae: 0.0555\n",
      "Epoch 11/15\n",
      "8000/8000 [==============================] - 54s 7ms/step - loss: 0.0608 - mae: 0.0205 - val_loss: 0.2027 - val_mae: 0.0621\n",
      "Epoch 12/15\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.0583 - mae: 0.0197 - val_loss: 0.1255 - val_mae: 0.0407\n",
      "Epoch 13/15\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.0556 - mae: 0.0188 - val_loss: 0.1755 - val_mae: 0.0537\n",
      "Epoch 14/15\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.0534 - mae: 0.0181 - val_loss: 0.1464 - val_mae: 0.0467\n",
      "Epoch 15/15\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.0518 - mae: 0.0175 - val_loss: 0.1989 - val_mae: 0.0568\n"
     ]
    }
   ],
   "source": [
    "#Mit Dice\n",
    "model = keras.models.Model(inputs=input_layer, outputs=x)\n",
    "model.compile(optimizer='adam', loss=bbdc2021.dice_loss, metrics=['mae'])\n",
    "history = model.fit(np.array(X_train),np.array(Y_train), batch_size=15, epochs=15, validation_data=(np.array(X_validation), np.array(Y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mit binary_crossentropy\n",
    "model = keras.models.Model(inputs=input_layer, outputs=x)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mae'])\n",
    "history = model.fit(np.array(X_train),np.array(Y_train), batch_size=15, epochs=15, validation_data=(np.array(X_validation), np.array(Y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "integrated-breeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.048, 12.   ]),\n",
       " array([ 0.096, 12.   ]),\n",
       " array([ 0.144, 12.   ]),\n",
       " array([ 0.192, 12.   ]),\n",
       " array([ 0.24, 12.  ]),\n",
       " array([ 0.288, 12.   ]),\n",
       " array([ 0.336, 12.   ]),\n",
       " array([ 0.384, 12.   ]),\n",
       " array([ 0.432, 12.   ]),\n",
       " array([ 0.48, 12.  ]),\n",
       " array([ 0.528, 12.   ]),\n",
       " array([ 0.576, 12.   ]),\n",
       " array([ 0.624, 12.   ]),\n",
       " array([ 0.672, 12.   ]),\n",
       " array([ 0.72, 12.  ]),\n",
       " array([ 0.768, 12.   ]),\n",
       " array([ 0.816, 12.   ]),\n",
       " array([ 0.864, 12.   ]),\n",
       " array([ 0.912, 12.   ]),\n",
       " array([ 0.96, 12.  ]),\n",
       " array([ 1.008, 12.   ]),\n",
       " array([ 1.056, 12.   ]),\n",
       " array([ 1.104, 12.   ]),\n",
       " array([ 1.152, 12.   ]),\n",
       " array([ 1.2, 12. ])]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "y_predicted = np.argmax(model.predict(np.array(X_test)), axis=2)\n",
    "y_predictedNew = np.zeros((y_predicted.shape[0]+1, y_predicted.shape[1]))\n",
    "y_predictedNew[0] = timepoints[1:]\n",
    "y_predictedNew[1:] = y_predicted\n",
    "\n",
    "result = np.transpose(y_predictedNew[0:2])\n",
    "result \n",
    "a = [list(group) for key, group in groupby(result, itemgetter(1))]\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "identified-headline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.048,  0.096,  0.144, ...,  9.888,  9.936,  9.984],\n",
       "       [12.   , 12.   , 12.   , ..., 12.   , 12.   , 12.   ],\n",
       "       [12.   , 12.   , 12.   , ..., 12.   , 12.   , 12.   ],\n",
       "       ...,\n",
       "       [12.   , 12.   , 12.   , ..., 12.   , 12.   , 12.   ],\n",
       "       [12.   , 12.   ,  0.   , ..., 12.   , 12.   , 12.   ],\n",
       "       [12.   , 12.   , 12.   , ..., 12.   , 12.   , 12.   ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = labelList[y_predicted][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-force",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
