{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greater-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './../')\n",
    "import numpy as np\n",
    "import bbdc2021 as bbdc\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "reload(bbdc)\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors \n",
    "import models.cnn.u_net_1d as unet\n",
    "reload(unet)\n",
    "import evaluation.evaluate as evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "peaceful-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "pathToDataset = \"dataset_fft_mel_l04_o02495_f32/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessible-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24009it [01:51, 214.45it/s]\n",
      "3047it [00:11, 269.53it/s]\n",
      "2988it [00:11, 268.79it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, timepoints, trainFileList = bbdc.load_data(\"train.csv\", pathToDataset+\"dev/\")\n",
    "X_validation, Y_validation, timepoints, validationFileList = bbdc.load_data(\"validation.csv\", pathToDataset+\"dev/\")  \n",
    "X_test, Y_test, timepoints, testFileList = bbdc.load_data(\"test.csv\", pathToDataset+\"dev/\")\n",
    "\n",
    "inputShape = X_train[0].shape\n",
    "input_layer = tf.keras.layers.Input(shape=(inputShape))\n",
    "numClasses = len(bbdc.LABEL_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "biological-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [32, 64, 90]\n",
    "modelsForSingleClasses = [unet.u_net(None, channels, lessParameter = True, numClasses=2, inputLayer = input_layer) for i in range(numClasses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imposed-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_classes = [np.expand_dims(Y_train[:,:,i], axis=-1) for i in range(numClasses)]\n",
    "Y_train_classes = [np.append(y, 1-y, axis=-1) for y in Y_train_classes]\n",
    "\n",
    "Y_validation_classes = [np.expand_dims(Y_validation[:,:,i], axis=-1) for i in range(numClasses)]\n",
    "Y_validation_classes = [np.append(y, 1-y, axis=-1) for y in Y_validation_classes]\n",
    "\n",
    "Y_test_classes = [np.expand_dims(Y_test[:,:,i], axis=-1) for i in range(numClasses)]\n",
    "Y_test_classes = [np.append(y, 1-y, axis=-1) for y in Y_test_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "connected-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsForSingleClasses = [keras.models.load_model(\"ForestLastEpoch/model\"+str(i)+\".h5\") for i in range(numClasses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bronze-blocking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainiere Modelle f√ºr Noise\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 19s 60ms/step - loss: 0.3186 - mae: 0.2175 - accuracy: 0.8834 - val_loss: 0.5209 - val_mae: 0.3636 - val_accuracy: 0.7109\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52086, saving model to model_0.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1810 - mae: 0.1049 - accuracy: 0.9305 - val_loss: 0.2138 - val_mae: 0.1179 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52086 to 0.21385, saving model to model_0.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1661 - mae: 0.0951 - accuracy: 0.9367 - val_loss: 0.1791 - val_mae: 0.0881 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21385 to 0.17911, saving model to model_0.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1579 - mae: 0.0905 - accuracy: 0.9403 - val_loss: 0.1694 - val_mae: 0.0915 - val_accuracy: 0.9366\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17911 to 0.16944, saving model to model_0.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1531 - mae: 0.0878 - accuracy: 0.9421 - val_loss: 0.1683 - val_mae: 0.0954 - val_accuracy: 0.9377\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.16944 to 0.16830, saving model to model_0.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1453 - mae: 0.0832 - accuracy: 0.9449 - val_loss: 0.1605 - val_mae: 0.0859 - val_accuracy: 0.9394\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16830 to 0.16047, saving model to model_0.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1380 - mae: 0.0788 - accuracy: 0.9481 - val_loss: 0.1552 - val_mae: 0.0850 - val_accuracy: 0.9417\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16047 to 0.15520, saving model to model_0.h5\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1370 - mae: 0.0778 - accuracy: 0.9488 - val_loss: 0.1590 - val_mae: 0.0796 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15520\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1304 - mae: 0.0739 - accuracy: 0.9516 - val_loss: 0.1559 - val_mae: 0.0766 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15520\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1289 - mae: 0.0726 - accuracy: 0.9523 - val_loss: 0.1563 - val_mae: 0.0793 - val_accuracy: 0.9428\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.15520\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1231 - mae: 0.0696 - accuracy: 0.9542 - val_loss: 0.1555 - val_mae: 0.0796 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.15520\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1252 - mae: 0.0709 - accuracy: 0.9534 - val_loss: 0.1525 - val_mae: 0.0762 - val_accuracy: 0.9442\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15520 to 0.15248, saving model to model_0.h5\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1240 - mae: 0.0700 - accuracy: 0.9542 - val_loss: 0.1565 - val_mae: 0.0892 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15248\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1194 - mae: 0.0675 - accuracy: 0.9559 - val_loss: 0.1588 - val_mae: 0.0763 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.15248\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1150 - mae: 0.0652 - accuracy: 0.9574 - val_loss: 0.1632 - val_mae: 0.0786 - val_accuracy: 0.9406\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.15248\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1117 - mae: 0.0630 - accuracy: 0.9588 - val_loss: 0.1564 - val_mae: 0.0741 - val_accuracy: 0.9435\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.15248\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1129 - mae: 0.0636 - accuracy: 0.9581 - val_loss: 0.1565 - val_mae: 0.0788 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15248\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.1138 - mae: 0.0641 - accuracy: 0.9579 - val_loss: 0.1561 - val_mae: 0.0697 - val_accuracy: 0.9455\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15248\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.1093 - mae: 0.0609 - accuracy: 0.9600 - val_loss: 0.1657 - val_mae: 0.0832 - val_accuracy: 0.9407\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15248\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.1087 - mae: 0.0615 - accuracy: 0.9597 - val_loss: 0.1622 - val_mae: 0.0716 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15248\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.1061 - mae: 0.0595 - accuracy: 0.9608 - val_loss: 0.1513 - val_mae: 0.0772 - val_accuracy: 0.9453\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15248 to 0.15131, saving model to model_0.h5\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.1029 - mae: 0.0580 - accuracy: 0.9621 - val_loss: 0.1597 - val_mae: 0.0698 - val_accuracy: 0.9447\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15131\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1045 - mae: 0.0589 - accuracy: 0.9612 - val_loss: 0.1612 - val_mae: 0.0706 - val_accuracy: 0.9450\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15131\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.1010 - mae: 0.0567 - accuracy: 0.9629 - val_loss: 0.1615 - val_mae: 0.0701 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15131\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.1003 - mae: 0.0564 - accuracy: 0.9629 - val_loss: 0.1698 - val_mae: 0.0757 - val_accuracy: 0.9425\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15131\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.1012 - mae: 0.0572 - accuracy: 0.9623 - val_loss: 0.1593 - val_mae: 0.0749 - val_accuracy: 0.9441\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.15131\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0984 - mae: 0.0557 - accuracy: 0.9632 - val_loss: 0.1638 - val_mae: 0.0802 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15131\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0968 - mae: 0.0547 - accuracy: 0.9640 - val_loss: 0.1631 - val_mae: 0.0712 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15131\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0958 - mae: 0.0544 - accuracy: 0.9642 - val_loss: 0.1614 - val_mae: 0.0730 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.15131\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0942 - mae: 0.0531 - accuracy: 0.9651 - val_loss: 0.1662 - val_mae: 0.0714 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15131\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0929 - mae: 0.0524 - accuracy: 0.9655 - val_loss: 0.1638 - val_mae: 0.0690 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15131\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0916 - mae: 0.0518 - accuracy: 0.9659 - val_loss: 0.1671 - val_mae: 0.0702 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.15131\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0905 - mae: 0.0509 - accuracy: 0.9665 - val_loss: 0.1668 - val_mae: 0.0683 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15131\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0905 - mae: 0.0512 - accuracy: 0.9661 - val_loss: 0.1598 - val_mae: 0.0767 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15131\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0911 - mae: 0.0515 - accuracy: 0.9660 - val_loss: 0.1742 - val_mae: 0.0658 - val_accuracy: 0.9449\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.15131\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0875 - mae: 0.0496 - accuracy: 0.9671 - val_loss: 0.1689 - val_mae: 0.0756 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.15131\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0886 - mae: 0.0506 - accuracy: 0.9666 - val_loss: 0.1811 - val_mae: 0.0695 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.15131\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0862 - mae: 0.0490 - accuracy: 0.9675 - val_loss: 0.1881 - val_mae: 0.0662 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.15131\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0836 - mae: 0.0475 - accuracy: 0.9687 - val_loss: 0.1680 - val_mae: 0.0748 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.15131\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0822 - mae: 0.0467 - accuracy: 0.9689 - val_loss: 0.1844 - val_mae: 0.0723 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.15131\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0829 - mae: 0.0471 - accuracy: 0.9687 - val_loss: 0.1708 - val_mae: 0.0676 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.15131\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0838 - mae: 0.0477 - accuracy: 0.9684 - val_loss: 0.1682 - val_mae: 0.0677 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.15131\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0839 - mae: 0.0478 - accuracy: 0.9684 - val_loss: 0.1719 - val_mae: 0.0690 - val_accuracy: 0.9438\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.15131\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0812 - mae: 0.0462 - accuracy: 0.9691 - val_loss: 0.1798 - val_mae: 0.0764 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.15131\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0822 - mae: 0.0468 - accuracy: 0.9691 - val_loss: 0.1720 - val_mae: 0.0698 - val_accuracy: 0.9436\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.15131\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0801 - mae: 0.0458 - accuracy: 0.9697 - val_loss: 0.1727 - val_mae: 0.0672 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.15131\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0800 - mae: 0.0454 - accuracy: 0.9700 - val_loss: 0.1700 - val_mae: 0.0725 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.15131\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0801 - mae: 0.0456 - accuracy: 0.9699 - val_loss: 0.1999 - val_mae: 0.0847 - val_accuracy: 0.9345\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.15131\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0776 - mae: 0.0445 - accuracy: 0.9704 - val_loss: 0.1787 - val_mae: 0.0778 - val_accuracy: 0.9411\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.15131\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0780 - mae: 0.0448 - accuracy: 0.9703 - val_loss: 0.1712 - val_mae: 0.0683 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.15131\n",
      "Trainiere Modelle f√ºr Bark\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 13s 36ms/step - loss: 0.2260 - mae: 0.1584 - accuracy: 0.9423 - val_loss: 0.1458 - val_mae: 0.0863 - val_accuracy: 0.9656\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14578, saving model to model_1.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0680 - mae: 0.0355 - accuracy: 0.9783 - val_loss: 0.0960 - val_mae: 0.0344 - val_accuracy: 0.9689\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14578 to 0.09595, saving model to model_1.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0638 - mae: 0.0326 - accuracy: 0.9797 - val_loss: 0.0594 - val_mae: 0.0321 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09595 to 0.05945, saving model to model_1.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0573 - mae: 0.0294 - accuracy: 0.9817 - val_loss: 0.0555 - val_mae: 0.0248 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05945 to 0.05550, saving model to model_1.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0554 - mae: 0.0288 - accuracy: 0.9819 - val_loss: 0.0552 - val_mae: 0.0253 - val_accuracy: 0.9820\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05550 to 0.05523, saving model to model_1.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0491 - mae: 0.0251 - accuracy: 0.9842 - val_loss: 0.0483 - val_mae: 0.0228 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05523 to 0.04830, saving model to model_1.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0474 - mae: 0.0242 - accuracy: 0.9846 - val_loss: 0.0506 - val_mae: 0.0277 - val_accuracy: 0.9834\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04830\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0443 - mae: 0.0228 - accuracy: 0.9854 - val_loss: 0.0500 - val_mae: 0.0237 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04830\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0411 - mae: 0.0214 - accuracy: 0.9864 - val_loss: 0.0494 - val_mae: 0.0190 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04830\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0392 - mae: 0.0201 - accuracy: 0.9873 - val_loss: 0.0466 - val_mae: 0.0195 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04830 to 0.04659, saving model to model_1.h5\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0386 - mae: 0.0200 - accuracy: 0.9872 - val_loss: 0.0590 - val_mae: 0.0219 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04659\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0355 - mae: 0.0184 - accuracy: 0.9881 - val_loss: 0.0512 - val_mae: 0.0246 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04659\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0359 - mae: 0.0187 - accuracy: 0.9879 - val_loss: 0.0520 - val_mae: 0.0281 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04659\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0338 - mae: 0.0177 - accuracy: 0.9888 - val_loss: 0.0554 - val_mae: 0.0175 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04659\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0304 - mae: 0.0160 - accuracy: 0.9897 - val_loss: 0.0844 - val_mae: 0.0433 - val_accuracy: 0.9690\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04659\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0302 - mae: 0.0159 - accuracy: 0.9899 - val_loss: 0.0472 - val_mae: 0.0202 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04659\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0295 - mae: 0.0151 - accuracy: 0.9902 - val_loss: 0.0496 - val_mae: 0.0235 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04659\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0283 - mae: 0.0150 - accuracy: 0.9904 - val_loss: 0.0520 - val_mae: 0.0175 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04659\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0278 - mae: 0.0144 - accuracy: 0.9908 - val_loss: 0.0484 - val_mae: 0.0166 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04659\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0258 - mae: 0.0134 - accuracy: 0.9912 - val_loss: 0.0474 - val_mae: 0.0169 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04659\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0259 - mae: 0.0136 - accuracy: 0.9911 - val_loss: 0.0846 - val_mae: 0.0403 - val_accuracy: 0.9699\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04659\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0233 - mae: 0.0125 - accuracy: 0.9921 - val_loss: 0.0572 - val_mae: 0.0236 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04659\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0237 - mae: 0.0126 - accuracy: 0.9918 - val_loss: 0.0537 - val_mae: 0.0200 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04659\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0243 - mae: 0.0128 - accuracy: 0.9916 - val_loss: 0.0590 - val_mae: 0.0162 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04659\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0203 - mae: 0.0109 - accuracy: 0.9931 - val_loss: 0.0512 - val_mae: 0.0159 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04659\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0202 - mae: 0.0108 - accuracy: 0.9930 - val_loss: 0.0572 - val_mae: 0.0252 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04659\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0196 - mae: 0.0105 - accuracy: 0.9933 - val_loss: 0.0555 - val_mae: 0.0214 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04659\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0179 - mae: 0.0098 - accuracy: 0.9938 - val_loss: 0.0526 - val_mae: 0.0186 - val_accuracy: 0.9849\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04659\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0188 - mae: 0.0103 - accuracy: 0.9935 - val_loss: 0.0638 - val_mae: 0.0183 - val_accuracy: 0.9853\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04659\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0197 - mae: 0.0106 - accuracy: 0.9930 - val_loss: 0.0530 - val_mae: 0.0179 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04659\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0178 - mae: 0.0096 - accuracy: 0.9935 - val_loss: 0.0571 - val_mae: 0.0155 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04659\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0152 - mae: 0.0084 - accuracy: 0.9947 - val_loss: 0.0585 - val_mae: 0.0156 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04659\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0154 - mae: 0.0082 - accuracy: 0.9946 - val_loss: 0.0502 - val_mae: 0.0171 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04659\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0152 - mae: 0.0084 - accuracy: 0.9945 - val_loss: 0.0567 - val_mae: 0.0157 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04659\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0168 - mae: 0.0091 - accuracy: 0.9940 - val_loss: 0.0527 - val_mae: 0.0168 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04659\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0135 - mae: 0.0076 - accuracy: 0.9951 - val_loss: 0.0563 - val_mae: 0.0167 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04659\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0140 - mae: 0.0079 - accuracy: 0.9949 - val_loss: 0.0572 - val_mae: 0.0168 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04659\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0125 - mae: 0.0071 - accuracy: 0.9954 - val_loss: 0.0567 - val_mae: 0.0165 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04659\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0144 - mae: 0.0078 - accuracy: 0.9949 - val_loss: 0.0546 - val_mae: 0.0163 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04659\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0121 - mae: 0.0068 - accuracy: 0.9955 - val_loss: 0.0726 - val_mae: 0.0172 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04659\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0121 - mae: 0.0068 - accuracy: 0.9957 - val_loss: 0.0638 - val_mae: 0.0202 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04659\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0135 - mae: 0.0075 - accuracy: 0.9950 - val_loss: 0.0589 - val_mae: 0.0147 - val_accuracy: 0.9872\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04659\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0109 - mae: 0.0061 - accuracy: 0.9959 - val_loss: 0.0599 - val_mae: 0.0157 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04659\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0129 - mae: 0.0072 - accuracy: 0.9952 - val_loss: 0.0742 - val_mae: 0.0152 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04659\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0121 - mae: 0.0066 - accuracy: 0.9955 - val_loss: 0.0631 - val_mae: 0.0172 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04659\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0105 - mae: 0.0060 - accuracy: 0.9961 - val_loss: 0.0699 - val_mae: 0.0216 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04659\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0124 - mae: 0.0068 - accuracy: 0.9955 - val_loss: 0.0702 - val_mae: 0.0177 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04659\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0106 - mae: 0.0062 - accuracy: 0.9960 - val_loss: 0.0607 - val_mae: 0.0160 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04659\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0111 - mae: 0.0063 - accuracy: 0.9959 - val_loss: 0.0634 - val_mae: 0.0154 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04659\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0108 - mae: 0.0061 - accuracy: 0.9959 - val_loss: 0.0615 - val_mae: 0.0141 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04659\n",
      "Trainiere Modelle f√ºr Burping_and_eructation\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 12s 34ms/step - loss: 0.2190 - mae: 0.1615 - accuracy: 0.9440 - val_loss: 0.1321 - val_mae: 0.0663 - val_accuracy: 0.9656\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13207, saving model to model_2.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0476 - mae: 0.0243 - accuracy: 0.9851 - val_loss: 0.0524 - val_mae: 0.0233 - val_accuracy: 0.9829\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13207 to 0.05237, saving model to model_2.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0381 - mae: 0.0195 - accuracy: 0.9882 - val_loss: 0.0363 - val_mae: 0.0138 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05237 to 0.03625, saving model to model_2.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0322 - mae: 0.0157 - accuracy: 0.9901 - val_loss: 0.0343 - val_mae: 0.0199 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03625 to 0.03430, saving model to model_2.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0294 - mae: 0.0148 - accuracy: 0.9908 - val_loss: 0.0364 - val_mae: 0.0171 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03430\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0253 - mae: 0.0127 - accuracy: 0.9922 - val_loss: 0.0273 - val_mae: 0.0112 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03430 to 0.02729, saving model to model_2.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0231 - mae: 0.0116 - accuracy: 0.9928 - val_loss: 0.0286 - val_mae: 0.0141 - val_accuracy: 0.9905\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02729\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0228 - mae: 0.0113 - accuracy: 0.9929 - val_loss: 0.0278 - val_mae: 0.0109 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02729\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0211 - mae: 0.0106 - accuracy: 0.9934 - val_loss: 0.0252 - val_mae: 0.0091 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02729 to 0.02516, saving model to model_2.h5\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0196 - mae: 0.0098 - accuracy: 0.9940 - val_loss: 0.0278 - val_mae: 0.0123 - val_accuracy: 0.9916\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02516\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0167 - mae: 0.0083 - accuracy: 0.9947 - val_loss: 0.0304 - val_mae: 0.0100 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02516\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0161 - mae: 0.0080 - accuracy: 0.9948 - val_loss: 0.0224 - val_mae: 0.0099 - val_accuracy: 0.9936\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02516 to 0.02238, saving model to model_2.h5\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0170 - mae: 0.0086 - accuracy: 0.9946 - val_loss: 0.0406 - val_mae: 0.0264 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02238\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0147 - mae: 0.0076 - accuracy: 0.9952 - val_loss: 0.0221 - val_mae: 0.0087 - val_accuracy: 0.9937\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02238 to 0.02210, saving model to model_2.h5\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0125 - mae: 0.0062 - accuracy: 0.9961 - val_loss: 0.0185 - val_mae: 0.0070 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02210 to 0.01855, saving model to model_2.h5\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0120 - mae: 0.0059 - accuracy: 0.9962 - val_loss: 0.0203 - val_mae: 0.0075 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01855\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0127 - mae: 0.0062 - accuracy: 0.9959 - val_loss: 0.0200 - val_mae: 0.0078 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01855\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0113 - mae: 0.0056 - accuracy: 0.9965 - val_loss: 0.0204 - val_mae: 0.0072 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01855\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0101 - mae: 0.0051 - accuracy: 0.9967 - val_loss: 0.0294 - val_mae: 0.0100 - val_accuracy: 0.9915\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01855\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0116 - mae: 0.0060 - accuracy: 0.9961 - val_loss: 0.0409 - val_mae: 0.0169 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01855\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0104 - mae: 0.0053 - accuracy: 0.9966 - val_loss: 0.0212 - val_mae: 0.0090 - val_accuracy: 0.9937\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01855\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0091 - mae: 0.0047 - accuracy: 0.9970 - val_loss: 0.0232 - val_mae: 0.0071 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01855\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0092 - mae: 0.0048 - accuracy: 0.9969 - val_loss: 0.0353 - val_mae: 0.0144 - val_accuracy: 0.9919\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01855\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0083 - mae: 0.0045 - accuracy: 0.9972 - val_loss: 0.0261 - val_mae: 0.0077 - val_accuracy: 0.9941\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01855\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0076 - mae: 0.0039 - accuracy: 0.9974 - val_loss: 0.0261 - val_mae: 0.0069 - val_accuracy: 0.9941\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01855\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0089 - mae: 0.0046 - accuracy: 0.9969 - val_loss: 0.0211 - val_mae: 0.0082 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01855\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0083 - mae: 0.0043 - accuracy: 0.9971 - val_loss: 0.0225 - val_mae: 0.0066 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01855\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0062 - mae: 0.0034 - accuracy: 0.9978 - val_loss: 0.0254 - val_mae: 0.0080 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01855\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0080 - mae: 0.0042 - accuracy: 0.9972 - val_loss: 0.0244 - val_mae: 0.0060 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01855\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0064 - mae: 0.0035 - accuracy: 0.9976 - val_loss: 0.0223 - val_mae: 0.0064 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01855\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0072 - mae: 0.0038 - accuracy: 0.9975 - val_loss: 0.0258 - val_mae: 0.0097 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01855\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0060 - mae: 0.0033 - accuracy: 0.9979 - val_loss: 0.0236 - val_mae: 0.0074 - val_accuracy: 0.9939\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01855\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0066 - mae: 0.0035 - accuracy: 0.9977 - val_loss: 0.0271 - val_mae: 0.0065 - val_accuracy: 0.9943\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01855\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0056 - mae: 0.0031 - accuracy: 0.9979 - val_loss: 0.0261 - val_mae: 0.0057 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01855\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0055 - mae: 0.0031 - accuracy: 0.9979 - val_loss: 0.0205 - val_mae: 0.0064 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01855\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0052 - mae: 0.0030 - accuracy: 0.9981 - val_loss: 0.0298 - val_mae: 0.0065 - val_accuracy: 0.9942\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01855\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0055 - mae: 0.0030 - accuracy: 0.9980 - val_loss: 0.0291 - val_mae: 0.0074 - val_accuracy: 0.9935\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01855\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0053 - mae: 0.0030 - accuracy: 0.9980 - val_loss: 0.0271 - val_mae: 0.0064 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01855\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0059 - mae: 0.0033 - accuracy: 0.9978 - val_loss: 0.0221 - val_mae: 0.0065 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01855\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0049 - mae: 0.0028 - accuracy: 0.9981 - val_loss: 0.0229 - val_mae: 0.0060 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01855\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0042 - mae: 0.0024 - accuracy: 0.9984 - val_loss: 0.0239 - val_mae: 0.0059 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01855\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0053 - mae: 0.0029 - accuracy: 0.9981 - val_loss: 0.0233 - val_mae: 0.0056 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01855\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0047 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0229 - val_mae: 0.0059 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01855\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0057 - mae: 0.0032 - accuracy: 0.9979 - val_loss: 0.0218 - val_mae: 0.0054 - val_accuracy: 0.9955\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01855\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0044 - mae: 0.0025 - accuracy: 0.9984 - val_loss: 0.0236 - val_mae: 0.0057 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01855\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0039 - mae: 0.0023 - accuracy: 0.9984 - val_loss: 0.0258 - val_mae: 0.0062 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01855\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0060 - mae: 0.0031 - accuracy: 0.9980 - val_loss: 0.0226 - val_mae: 0.0058 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01855\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0043 - mae: 0.0025 - accuracy: 0.9983 - val_loss: 0.0233 - val_mae: 0.0057 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01855\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0044 - mae: 0.0025 - accuracy: 0.9983 - val_loss: 0.0220 - val_mae: 0.0051 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01855\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0050 - mae: 0.0028 - accuracy: 0.9981 - val_loss: 0.0239 - val_mae: 0.0050 - val_accuracy: 0.9956\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01855\n",
      "Trainiere Modelle f√ºr Camera\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 14s 39ms/step - loss: 0.2661 - mae: 0.1937 - accuracy: 0.9111 - val_loss: 0.1448 - val_mae: 0.0739 - val_accuracy: 0.9621\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14480, saving model to model_3.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0760 - mae: 0.0412 - accuracy: 0.9738 - val_loss: 0.1207 - val_mae: 0.0374 - val_accuracy: 0.9626\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14480 to 0.12075, saving model to model_3.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0622 - mae: 0.0329 - accuracy: 0.9791 - val_loss: 0.0573 - val_mae: 0.0290 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12075 to 0.05729, saving model to model_3.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0521 - mae: 0.0273 - accuracy: 0.9827 - val_loss: 0.0572 - val_mae: 0.0288 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05729 to 0.05721, saving model to model_3.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0474 - mae: 0.0247 - accuracy: 0.9843 - val_loss: 0.0549 - val_mae: 0.0277 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05721 to 0.05492, saving model to model_3.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0435 - mae: 0.0229 - accuracy: 0.9856 - val_loss: 0.1076 - val_mae: 0.0303 - val_accuracy: 0.9713\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05492\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0385 - mae: 0.0203 - accuracy: 0.9870 - val_loss: 0.0544 - val_mae: 0.0314 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05492 to 0.05440, saving model to model_3.h5\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0360 - mae: 0.0190 - accuracy: 0.9880 - val_loss: 0.0481 - val_mae: 0.0226 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05440 to 0.04806, saving model to model_3.h5\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0338 - mae: 0.0176 - accuracy: 0.9885 - val_loss: 0.0509 - val_mae: 0.0217 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04806\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0343 - mae: 0.0178 - accuracy: 0.9886 - val_loss: 0.0412 - val_mae: 0.0201 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04806 to 0.04122, saving model to model_3.h5\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0305 - mae: 0.0163 - accuracy: 0.9897 - val_loss: 0.0430 - val_mae: 0.0194 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04122\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0280 - mae: 0.0146 - accuracy: 0.9907 - val_loss: 0.0484 - val_mae: 0.0171 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04122\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0258 - mae: 0.0132 - accuracy: 0.9915 - val_loss: 0.0439 - val_mae: 0.0210 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04122\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0264 - mae: 0.0136 - accuracy: 0.9912 - val_loss: 0.0448 - val_mae: 0.0195 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04122\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0240 - mae: 0.0125 - accuracy: 0.9920 - val_loss: 0.0784 - val_mae: 0.0210 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04122\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0247 - mae: 0.0125 - accuracy: 0.9917 - val_loss: 0.0425 - val_mae: 0.0169 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04122\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0213 - mae: 0.0113 - accuracy: 0.9929 - val_loss: 0.0439 - val_mae: 0.0182 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04122\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0209 - mae: 0.0111 - accuracy: 0.9929 - val_loss: 0.0411 - val_mae: 0.0157 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04122 to 0.04108, saving model to model_3.h5\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0202 - mae: 0.0107 - accuracy: 0.9932 - val_loss: 0.0540 - val_mae: 0.0168 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04108\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0212 - mae: 0.0111 - accuracy: 0.9928 - val_loss: 0.0559 - val_mae: 0.0207 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04108\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0186 - mae: 0.0099 - accuracy: 0.9936 - val_loss: 0.0450 - val_mae: 0.0156 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04108\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0170 - mae: 0.0089 - accuracy: 0.9943 - val_loss: 0.0433 - val_mae: 0.0128 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04108\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0169 - mae: 0.0088 - accuracy: 0.9943 - val_loss: 0.0424 - val_mae: 0.0137 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04108\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0160 - mae: 0.0085 - accuracy: 0.9945 - val_loss: 0.0583 - val_mae: 0.0151 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04108\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0157 - mae: 0.0083 - accuracy: 0.9945 - val_loss: 0.0434 - val_mae: 0.0141 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04108\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0168 - mae: 0.0091 - accuracy: 0.9941 - val_loss: 0.0476 - val_mae: 0.0200 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04108\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0143 - mae: 0.0078 - accuracy: 0.9950 - val_loss: 0.0439 - val_mae: 0.0135 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04108\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0135 - mae: 0.0073 - accuracy: 0.9952 - val_loss: 0.0796 - val_mae: 0.0183 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04108\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0163 - mae: 0.0084 - accuracy: 0.9945 - val_loss: 0.0455 - val_mae: 0.0137 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04108\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0131 - mae: 0.0071 - accuracy: 0.9954 - val_loss: 0.0466 - val_mae: 0.0154 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04108\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0131 - mae: 0.0073 - accuracy: 0.9951 - val_loss: 0.0497 - val_mae: 0.0160 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04108\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0122 - mae: 0.0068 - accuracy: 0.9957 - val_loss: 0.0512 - val_mae: 0.0187 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04108\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0111 - mae: 0.0062 - accuracy: 0.9959 - val_loss: 0.0592 - val_mae: 0.0136 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04108\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0105 - mae: 0.0058 - accuracy: 0.9963 - val_loss: 0.0531 - val_mae: 0.0131 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04108\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0104 - mae: 0.0056 - accuracy: 0.9963 - val_loss: 0.0496 - val_mae: 0.0129 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04108\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0117 - mae: 0.0064 - accuracy: 0.9957 - val_loss: 0.0488 - val_mae: 0.0145 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04108\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0105 - mae: 0.0059 - accuracy: 0.9960 - val_loss: 0.0470 - val_mae: 0.0128 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04108\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0110 - mae: 0.0060 - accuracy: 0.9961 - val_loss: 0.0545 - val_mae: 0.0149 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04108\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0092 - mae: 0.0054 - accuracy: 0.9966 - val_loss: 0.0515 - val_mae: 0.0149 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04108\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0078 - mae: 0.0044 - accuracy: 0.9971 - val_loss: 0.0509 - val_mae: 0.0127 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04108\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0095 - mae: 0.0054 - accuracy: 0.9965 - val_loss: 0.0495 - val_mae: 0.0131 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04108\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0074 - mae: 0.0041 - accuracy: 0.9973 - val_loss: 0.0657 - val_mae: 0.0230 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04108\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0086 - mae: 0.0048 - accuracy: 0.9969 - val_loss: 0.0528 - val_mae: 0.0139 - val_accuracy: 0.9880\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04108\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0087 - mae: 0.0049 - accuracy: 0.9968 - val_loss: 0.0543 - val_mae: 0.0123 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04108\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0093 - mae: 0.0052 - accuracy: 0.9966 - val_loss: 0.0598 - val_mae: 0.0117 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04108\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0073 - mae: 0.0040 - accuracy: 0.9973 - val_loss: 0.0473 - val_mae: 0.0137 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04108\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0075 - mae: 0.0044 - accuracy: 0.9972 - val_loss: 0.0505 - val_mae: 0.0134 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04108\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0075 - mae: 0.0042 - accuracy: 0.9972 - val_loss: 0.0533 - val_mae: 0.0142 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04108\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0097 - mae: 0.0054 - accuracy: 0.9964 - val_loss: 0.0521 - val_mae: 0.0118 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04108\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0061 - mae: 0.0035 - accuracy: 0.9977 - val_loss: 0.0748 - val_mae: 0.0154 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04108\n",
      "Trainiere Modelle f√ºr Cheering\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 14s 40ms/step - loss: 0.2555 - mae: 0.1896 - accuracy: 0.9183 - val_loss: 0.1497 - val_mae: 0.0700 - val_accuracy: 0.9597\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14969, saving model to model_4.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0641 - mae: 0.0347 - accuracy: 0.9778 - val_loss: 0.0787 - val_mae: 0.0446 - val_accuracy: 0.9709\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14969 to 0.07868, saving model to model_4.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0548 - mae: 0.0293 - accuracy: 0.9813 - val_loss: 0.0502 - val_mae: 0.0307 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07868 to 0.05016, saving model to model_4.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0470 - mae: 0.0254 - accuracy: 0.9838 - val_loss: 0.0667 - val_mae: 0.0381 - val_accuracy: 0.9736\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05016\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0422 - mae: 0.0232 - accuracy: 0.9849 - val_loss: 0.0485 - val_mae: 0.0207 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05016 to 0.04848, saving model to model_4.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0383 - mae: 0.0210 - accuracy: 0.9863 - val_loss: 0.0472 - val_mae: 0.0213 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04848 to 0.04718, saving model to model_4.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0361 - mae: 0.0194 - accuracy: 0.9873 - val_loss: 0.0463 - val_mae: 0.0224 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04718 to 0.04634, saving model to model_4.h5\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0317 - mae: 0.0175 - accuracy: 0.9888 - val_loss: 0.0390 - val_mae: 0.0204 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04634 to 0.03895, saving model to model_4.h5\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0315 - mae: 0.0170 - accuracy: 0.9892 - val_loss: 0.0526 - val_mae: 0.0265 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03895\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0290 - mae: 0.0158 - accuracy: 0.9897 - val_loss: 0.0456 - val_mae: 0.0216 - val_accuracy: 0.9848\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03895\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0259 - mae: 0.0139 - accuracy: 0.9912 - val_loss: 0.0401 - val_mae: 0.0200 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.03895\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0249 - mae: 0.0129 - accuracy: 0.9914 - val_loss: 0.0429 - val_mae: 0.0187 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03895\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0225 - mae: 0.0124 - accuracy: 0.9920 - val_loss: 0.0401 - val_mae: 0.0207 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03895\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0206 - mae: 0.0110 - accuracy: 0.9930 - val_loss: 0.0396 - val_mae: 0.0155 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03895\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0197 - mae: 0.0103 - accuracy: 0.9934 - val_loss: 0.0864 - val_mae: 0.0255 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03895\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0216 - mae: 0.0115 - accuracy: 0.9925 - val_loss: 0.0454 - val_mae: 0.0159 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03895\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0175 - mae: 0.0094 - accuracy: 0.9940 - val_loss: 0.0502 - val_mae: 0.0170 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.03895\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0156 - mae: 0.0082 - accuracy: 0.9946 - val_loss: 0.0389 - val_mae: 0.0151 - val_accuracy: 0.9880\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.03895 to 0.03895, saving model to model_4.h5\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0177 - mae: 0.0093 - accuracy: 0.9939 - val_loss: 0.0375 - val_mae: 0.0142 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.03895 to 0.03752, saving model to model_4.h5\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0149 - mae: 0.0080 - accuracy: 0.9947 - val_loss: 0.0460 - val_mae: 0.0215 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.03752\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0154 - mae: 0.0081 - accuracy: 0.9947 - val_loss: 0.0370 - val_mae: 0.0148 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.03752 to 0.03705, saving model to model_4.h5\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0128 - mae: 0.0070 - accuracy: 0.9955 - val_loss: 0.0433 - val_mae: 0.0154 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.03705\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0145 - mae: 0.0077 - accuracy: 0.9951 - val_loss: 0.0418 - val_mae: 0.0145 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03705\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0120 - mae: 0.0066 - accuracy: 0.9958 - val_loss: 0.0480 - val_mae: 0.0178 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03705\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0115 - mae: 0.0063 - accuracy: 0.9959 - val_loss: 0.0445 - val_mae: 0.0154 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03705\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0131 - mae: 0.0071 - accuracy: 0.9954 - val_loss: 0.0389 - val_mae: 0.0155 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03705\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0098 - mae: 0.0055 - accuracy: 0.9965 - val_loss: 0.0415 - val_mae: 0.0131 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03705\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0087 - mae: 0.0048 - accuracy: 0.9969 - val_loss: 0.0443 - val_mae: 0.0126 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03705\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0096 - mae: 0.0052 - accuracy: 0.9965 - val_loss: 0.0490 - val_mae: 0.0140 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03705\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0097 - mae: 0.0052 - accuracy: 0.9966 - val_loss: 0.0503 - val_mae: 0.0135 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03705\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0091 - mae: 0.0051 - accuracy: 0.9967 - val_loss: 0.0488 - val_mae: 0.0133 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.03705\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0091 - mae: 0.0050 - accuracy: 0.9966 - val_loss: 0.0484 - val_mae: 0.0168 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03705\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0084 - mae: 0.0048 - accuracy: 0.9969 - val_loss: 0.0519 - val_mae: 0.0157 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03705\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0083 - mae: 0.0047 - accuracy: 0.9970 - val_loss: 0.0483 - val_mae: 0.0133 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03705\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0085 - mae: 0.0047 - accuracy: 0.9970 - val_loss: 0.0509 - val_mae: 0.0137 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03705\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0094 - mae: 0.0052 - accuracy: 0.9965 - val_loss: 0.0522 - val_mae: 0.0140 - val_accuracy: 0.9872\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03705\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0065 - mae: 0.0037 - accuracy: 0.9976 - val_loss: 0.0476 - val_mae: 0.0136 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03705\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0066 - mae: 0.0036 - accuracy: 0.9977 - val_loss: 0.0551 - val_mae: 0.0151 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03705\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0067 - mae: 0.0039 - accuracy: 0.9975 - val_loss: 0.0434 - val_mae: 0.0136 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03705\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0078 - mae: 0.0046 - accuracy: 0.9971 - val_loss: 0.0535 - val_mae: 0.0129 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03705\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0070 - mae: 0.0040 - accuracy: 0.9974 - val_loss: 0.0510 - val_mae: 0.0124 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03705\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0075 - mae: 0.0043 - accuracy: 0.9972 - val_loss: 0.0601 - val_mae: 0.0136 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03705\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0068 - mae: 0.0038 - accuracy: 0.9975 - val_loss: 0.0530 - val_mae: 0.0129 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03705\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0056 - mae: 0.0033 - accuracy: 0.9979 - val_loss: 0.0550 - val_mae: 0.0122 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03705\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0061 - mae: 0.0033 - accuracy: 0.9978 - val_loss: 0.0562 - val_mae: 0.0158 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03705\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0072 - mae: 0.0041 - accuracy: 0.9973 - val_loss: 0.0525 - val_mae: 0.0119 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03705\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0061 - mae: 0.0034 - accuracy: 0.9977 - val_loss: 0.0510 - val_mae: 0.0121 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03705\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0062 - mae: 0.0035 - accuracy: 0.9976 - val_loss: 0.0604 - val_mae: 0.0134 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03705\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0062 - mae: 0.0034 - accuracy: 0.9977 - val_loss: 0.0479 - val_mae: 0.0147 - val_accuracy: 0.9872\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03705\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0065 - mae: 0.0038 - accuracy: 0.9976 - val_loss: 0.0529 - val_mae: 0.0115 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03705\n",
      "Trainiere Modelle f√ºr Church_bell\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 14s 40ms/step - loss: 0.2552 - mae: 0.1891 - accuracy: 0.9183 - val_loss: 0.1670 - val_mae: 0.0558 - val_accuracy: 0.9595\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16704, saving model to model_5.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0473 - mae: 0.0264 - accuracy: 0.9833 - val_loss: 0.0562 - val_mae: 0.0265 - val_accuracy: 0.9797\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16704 to 0.05620, saving model to model_5.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0366 - mae: 0.0202 - accuracy: 0.9866 - val_loss: 0.0450 - val_mae: 0.0188 - val_accuracy: 0.9842\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05620 to 0.04504, saving model to model_5.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0315 - mae: 0.0174 - accuracy: 0.9885 - val_loss: 0.0389 - val_mae: 0.0153 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04504 to 0.03888, saving model to model_5.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0258 - mae: 0.0140 - accuracy: 0.9909 - val_loss: 0.0347 - val_mae: 0.0188 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03888 to 0.03469, saving model to model_5.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0246 - mae: 0.0136 - accuracy: 0.9912 - val_loss: 0.0287 - val_mae: 0.0117 - val_accuracy: 0.9907\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03469 to 0.02869, saving model to model_5.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0214 - mae: 0.0117 - accuracy: 0.9925 - val_loss: 0.0295 - val_mae: 0.0163 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02869\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0191 - mae: 0.0105 - accuracy: 0.9933 - val_loss: 0.0268 - val_mae: 0.0113 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02869 to 0.02685, saving model to model_5.h5\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0191 - mae: 0.0103 - accuracy: 0.9931 - val_loss: 0.0461 - val_mae: 0.0186 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02685\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0179 - mae: 0.0096 - accuracy: 0.9935 - val_loss: 0.0313 - val_mae: 0.0114 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02685\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0156 - mae: 0.0088 - accuracy: 0.9946 - val_loss: 0.0288 - val_mae: 0.0122 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02685\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0147 - mae: 0.0080 - accuracy: 0.9947 - val_loss: 0.0237 - val_mae: 0.0085 - val_accuracy: 0.9930\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02685 to 0.02370, saving model to model_5.h5\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0126 - mae: 0.0069 - accuracy: 0.9955 - val_loss: 0.0269 - val_mae: 0.0098 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02370\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0136 - mae: 0.0076 - accuracy: 0.9952 - val_loss: 0.0247 - val_mae: 0.0096 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02370\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0116 - mae: 0.0064 - accuracy: 0.9959 - val_loss: 0.0213 - val_mae: 0.0092 - val_accuracy: 0.9935\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02370 to 0.02132, saving model to model_5.h5\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0115 - mae: 0.0064 - accuracy: 0.9958 - val_loss: 0.0255 - val_mae: 0.0116 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02132\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0095 - mae: 0.0054 - accuracy: 0.9965 - val_loss: 0.0315 - val_mae: 0.0103 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02132\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0101 - mae: 0.0055 - accuracy: 0.9963 - val_loss: 0.0267 - val_mae: 0.0102 - val_accuracy: 0.9916\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02132\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0084 - mae: 0.0047 - accuracy: 0.9968 - val_loss: 0.0274 - val_mae: 0.0100 - val_accuracy: 0.9919\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02132\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0091 - mae: 0.0051 - accuracy: 0.9967 - val_loss: 0.0301 - val_mae: 0.0088 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02132\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0095 - mae: 0.0053 - accuracy: 0.9964 - val_loss: 0.0298 - val_mae: 0.0080 - val_accuracy: 0.9930\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02132\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0079 - mae: 0.0043 - accuracy: 0.9971 - val_loss: 0.0338 - val_mae: 0.0089 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02132\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0083 - mae: 0.0046 - accuracy: 0.9970 - val_loss: 0.0266 - val_mae: 0.0099 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02132\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0070 - mae: 0.0039 - accuracy: 0.9974 - val_loss: 0.0262 - val_mae: 0.0083 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.02132\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0061 - mae: 0.0035 - accuracy: 0.9977 - val_loss: 0.0221 - val_mae: 0.0081 - val_accuracy: 0.9935\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02132\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0059 - mae: 0.0033 - accuracy: 0.9978 - val_loss: 0.0286 - val_mae: 0.0088 - val_accuracy: 0.9924\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02132\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0074 - mae: 0.0041 - accuracy: 0.9973 - val_loss: 0.0289 - val_mae: 0.0092 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.02132\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0067 - mae: 0.0038 - accuracy: 0.9975 - val_loss: 0.0294 - val_mae: 0.0077 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.02132\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0063 - mae: 0.0035 - accuracy: 0.9976 - val_loss: 0.0248 - val_mae: 0.0081 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.02132\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0054 - mae: 0.0030 - accuracy: 0.9980 - val_loss: 0.0382 - val_mae: 0.0086 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.02132\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0057 - mae: 0.0031 - accuracy: 0.9979 - val_loss: 0.0307 - val_mae: 0.0081 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.02132\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0054 - mae: 0.0029 - accuracy: 0.9980 - val_loss: 0.0343 - val_mae: 0.0077 - val_accuracy: 0.9930\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.02132\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0041 - mae: 0.0024 - accuracy: 0.9984 - val_loss: 0.0420 - val_mae: 0.0108 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.02132\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0064 - mae: 0.0035 - accuracy: 0.9976 - val_loss: 0.0300 - val_mae: 0.0077 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.02132\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0037 - mae: 0.0022 - accuracy: 0.9986 - val_loss: 0.0365 - val_mae: 0.0074 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.02132\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0043 - mae: 0.0025 - accuracy: 0.9984 - val_loss: 0.0318 - val_mae: 0.0074 - val_accuracy: 0.9934\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.02132\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0046 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0321 - val_mae: 0.0075 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.02132\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0047 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0286 - val_mae: 0.0088 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.02132\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0031 - mae: 0.0018 - accuracy: 0.9988 - val_loss: 0.0297 - val_mae: 0.0077 - val_accuracy: 0.9928\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.02132\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0055 - mae: 0.0030 - accuracy: 0.9979 - val_loss: 0.0260 - val_mae: 0.0084 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.02132\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0046 - mae: 0.0025 - accuracy: 0.9983 - val_loss: 0.0329 - val_mae: 0.0081 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.02132\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0050 - mae: 0.0029 - accuracy: 0.9981 - val_loss: 0.0280 - val_mae: 0.0079 - val_accuracy: 0.9931\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.02132\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0058 - mae: 0.0033 - accuracy: 0.9978 - val_loss: 0.0382 - val_mae: 0.0077 - val_accuracy: 0.9929\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.02132\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0040 - mae: 0.0023 - accuracy: 0.9984 - val_loss: 0.0294 - val_mae: 0.0072 - val_accuracy: 0.9936\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.02132\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0045 - mae: 0.0026 - accuracy: 0.9983 - val_loss: 0.0329 - val_mae: 0.0094 - val_accuracy: 0.9916\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.02132\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0042 - mae: 0.0025 - accuracy: 0.9984 - val_loss: 0.0304 - val_mae: 0.0083 - val_accuracy: 0.9928\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.02132\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0035 - mae: 0.0020 - accuracy: 0.9987 - val_loss: 0.0303 - val_mae: 0.0071 - val_accuracy: 0.9935\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.02132\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0047 - mae: 0.0025 - accuracy: 0.9983 - val_loss: 0.0264 - val_mae: 0.0091 - val_accuracy: 0.9926\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.02132\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0034 - mae: 0.0020 - accuracy: 0.9987 - val_loss: 0.0273 - val_mae: 0.0073 - val_accuracy: 0.9935\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.02132\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0023 - mae: 0.0014 - accuracy: 0.9991 - val_loss: 0.0266 - val_mae: 0.0063 - val_accuracy: 0.9943\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.02132\n",
      "Trainiere Modelle f√ºr Cough\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 13s 38ms/step - loss: 0.2288 - mae: 0.1640 - accuracy: 0.9463 - val_loss: 0.1445 - val_mae: 0.0801 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14455, saving model to model_6.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0701 - mae: 0.0361 - accuracy: 0.9783 - val_loss: 0.1212 - val_mae: 0.0350 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14455 to 0.12120, saving model to model_6.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0555 - mae: 0.0280 - accuracy: 0.9828 - val_loss: 0.0510 - val_mae: 0.0249 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12120 to 0.05103, saving model to model_6.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0507 - mae: 0.0256 - accuracy: 0.9842 - val_loss: 0.0531 - val_mae: 0.0265 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05103\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0456 - mae: 0.0228 - accuracy: 0.9860 - val_loss: 0.0463 - val_mae: 0.0195 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05103 to 0.04627, saving model to model_6.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0414 - mae: 0.0202 - accuracy: 0.9872 - val_loss: 0.0766 - val_mae: 0.0414 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04627\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 34ms/step - loss: 0.0378 - mae: 0.0186 - accuracy: 0.9883 - val_loss: 0.0576 - val_mae: 0.0278 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04627\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0333 - mae: 0.0168 - accuracy: 0.9896 - val_loss: 0.0535 - val_mae: 0.0270 - val_accuracy: 0.9822\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04627\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0331 - mae: 0.0166 - accuracy: 0.9895 - val_loss: 0.0487 - val_mae: 0.0251 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04627\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0309 - mae: 0.0151 - accuracy: 0.9906 - val_loss: 0.0411 - val_mae: 0.0214 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04627 to 0.04107, saving model to model_6.h5\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0288 - mae: 0.0143 - accuracy: 0.9911 - val_loss: 0.0441 - val_mae: 0.0163 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04107\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0277 - mae: 0.0137 - accuracy: 0.9914 - val_loss: 0.0500 - val_mae: 0.0239 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04107\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0291 - mae: 0.0146 - accuracy: 0.9908 - val_loss: 0.0486 - val_mae: 0.0168 - val_accuracy: 0.9871\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04107\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0247 - mae: 0.0122 - accuracy: 0.9924 - val_loss: 0.0552 - val_mae: 0.0237 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04107\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0255 - mae: 0.0131 - accuracy: 0.9919 - val_loss: 0.0430 - val_mae: 0.0163 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04107\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0216 - mae: 0.0108 - accuracy: 0.9931 - val_loss: 0.0472 - val_mae: 0.0158 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04107\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0220 - mae: 0.0111 - accuracy: 0.9930 - val_loss: 0.0497 - val_mae: 0.0217 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04107\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0218 - mae: 0.0111 - accuracy: 0.9930 - val_loss: 0.0503 - val_mae: 0.0221 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04107\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0227 - mae: 0.0114 - accuracy: 0.9927 - val_loss: 0.0429 - val_mae: 0.0141 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04107\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0197 - mae: 0.0098 - accuracy: 0.9936 - val_loss: 0.0421 - val_mae: 0.0144 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04107\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0171 - mae: 0.0088 - accuracy: 0.9945 - val_loss: 0.0467 - val_mae: 0.0149 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04107\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0172 - mae: 0.0089 - accuracy: 0.9944 - val_loss: 0.0445 - val_mae: 0.0135 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04107\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0164 - mae: 0.0084 - accuracy: 0.9945 - val_loss: 0.0457 - val_mae: 0.0174 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04107\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0168 - mae: 0.0088 - accuracy: 0.9944 - val_loss: 0.0463 - val_mae: 0.0189 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04107\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0164 - mae: 0.0087 - accuracy: 0.9944 - val_loss: 0.0459 - val_mae: 0.0159 - val_accuracy: 0.9880\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04107\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0141 - mae: 0.0076 - accuracy: 0.9952 - val_loss: 0.0414 - val_mae: 0.0148 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04107\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0135 - mae: 0.0073 - accuracy: 0.9954 - val_loss: 0.0607 - val_mae: 0.0242 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04107\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 0.0136 - mae: 0.0074 - accuracy: 0.9954 - val_loss: 0.0498 - val_mae: 0.0177 - val_accuracy: 0.9857\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04107\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0123 - mae: 0.0067 - accuracy: 0.9957 - val_loss: 0.0474 - val_mae: 0.0133 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04107\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0138 - mae: 0.0073 - accuracy: 0.9953 - val_loss: 0.0482 - val_mae: 0.0185 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04107\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0136 - mae: 0.0073 - accuracy: 0.9952 - val_loss: 0.0531 - val_mae: 0.0173 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04107\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0116 - mae: 0.0064 - accuracy: 0.9959 - val_loss: 0.0531 - val_mae: 0.0132 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04107\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0106 - mae: 0.0058 - accuracy: 0.9962 - val_loss: 0.0540 - val_mae: 0.0193 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04107\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0108 - mae: 0.0059 - accuracy: 0.9962 - val_loss: 0.0519 - val_mae: 0.0169 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04107\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0100 - mae: 0.0055 - accuracy: 0.9964 - val_loss: 0.0550 - val_mae: 0.0162 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04107\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0114 - mae: 0.0061 - accuracy: 0.9960 - val_loss: 0.0603 - val_mae: 0.0216 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04107\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0107 - mae: 0.0059 - accuracy: 0.9962 - val_loss: 0.0528 - val_mae: 0.0136 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04107\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0089 - mae: 0.0049 - accuracy: 0.9968 - val_loss: 0.0552 - val_mae: 0.0138 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04107\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0094 - mae: 0.0052 - accuracy: 0.9967 - val_loss: 0.0545 - val_mae: 0.0136 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04107\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0096 - mae: 0.0053 - accuracy: 0.9965 - val_loss: 0.0560 - val_mae: 0.0128 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04107\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0100 - mae: 0.0057 - accuracy: 0.9963 - val_loss: 0.0505 - val_mae: 0.0133 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04107\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0089 - mae: 0.0049 - accuracy: 0.9968 - val_loss: 0.0550 - val_mae: 0.0120 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04107\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0097 - mae: 0.0053 - accuracy: 0.9965 - val_loss: 0.0541 - val_mae: 0.0144 - val_accuracy: 0.9880\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04107\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0089 - mae: 0.0049 - accuracy: 0.9968 - val_loss: 0.0554 - val_mae: 0.0132 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04107\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0076 - mae: 0.0042 - accuracy: 0.9972 - val_loss: 0.0517 - val_mae: 0.0136 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04107\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0078 - mae: 0.0043 - accuracy: 0.9971 - val_loss: 0.0634 - val_mae: 0.0145 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04107\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0104 - mae: 0.0057 - accuracy: 0.9963 - val_loss: 0.0567 - val_mae: 0.0131 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04107\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0077 - mae: 0.0044 - accuracy: 0.9971 - val_loss: 0.0553 - val_mae: 0.0121 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04107\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0074 - mae: 0.0041 - accuracy: 0.9973 - val_loss: 0.0581 - val_mae: 0.0167 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04107\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0089 - mae: 0.0050 - accuracy: 0.9966 - val_loss: 0.0585 - val_mae: 0.0121 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04107\n",
      "Trainiere Modelle f√ºr Doorbell\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 13s 38ms/step - loss: 0.1962 - mae: 0.1421 - accuracy: 0.9601 - val_loss: 0.1496 - val_mae: 0.0697 - val_accuracy: 0.9618\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14958, saving model to model_7.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0483 - mae: 0.0252 - accuracy: 0.9847 - val_loss: 0.0420 - val_mae: 0.0184 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14958 to 0.04202, saving model to model_7.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0317 - mae: 0.0162 - accuracy: 0.9899 - val_loss: 0.0288 - val_mae: 0.0163 - val_accuracy: 0.9907\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04202 to 0.02875, saving model to model_7.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0263 - mae: 0.0134 - accuracy: 0.9916 - val_loss: 0.0211 - val_mae: 0.0090 - val_accuracy: 0.9936\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02875 to 0.02115, saving model to model_7.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0243 - mae: 0.0121 - accuracy: 0.9924 - val_loss: 0.0203 - val_mae: 0.0106 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02115 to 0.02025, saving model to model_7.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0196 - mae: 0.0102 - accuracy: 0.9936 - val_loss: 0.0178 - val_mae: 0.0093 - val_accuracy: 0.9941\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02025 to 0.01784, saving model to model_7.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0175 - mae: 0.0089 - accuracy: 0.9944 - val_loss: 0.0154 - val_mae: 0.0070 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01784 to 0.01543, saving model to model_7.h5\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0140 - mae: 0.0073 - accuracy: 0.9954 - val_loss: 0.0261 - val_mae: 0.0126 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01543\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0142 - mae: 0.0073 - accuracy: 0.9954 - val_loss: 0.0152 - val_mae: 0.0067 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01543 to 0.01522, saving model to model_7.h5\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0118 - mae: 0.0061 - accuracy: 0.9960 - val_loss: 0.0223 - val_mae: 0.0084 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01522\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0114 - mae: 0.0060 - accuracy: 0.9961 - val_loss: 0.0237 - val_mae: 0.0099 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01522\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0109 - mae: 0.0057 - accuracy: 0.9963 - val_loss: 0.0126 - val_mae: 0.0054 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01522 to 0.01260, saving model to model_7.h5\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0090 - mae: 0.0048 - accuracy: 0.9970 - val_loss: 0.0156 - val_mae: 0.0069 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01260\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0077 - mae: 0.0040 - accuracy: 0.9974 - val_loss: 0.0148 - val_mae: 0.0052 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01260\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0069 - mae: 0.0037 - accuracy: 0.9976 - val_loss: 0.0295 - val_mae: 0.0137 - val_accuracy: 0.9899\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01260\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0086 - mae: 0.0046 - accuracy: 0.9971 - val_loss: 0.0157 - val_mae: 0.0077 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01260\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0064 - mae: 0.0036 - accuracy: 0.9978 - val_loss: 0.0152 - val_mae: 0.0071 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01260\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0071 - mae: 0.0039 - accuracy: 0.9975 - val_loss: 0.0126 - val_mae: 0.0046 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01260 to 0.01257, saving model to model_7.h5\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0055 - mae: 0.0030 - accuracy: 0.9981 - val_loss: 0.0164 - val_mae: 0.0063 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01257\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0061 - mae: 0.0032 - accuracy: 0.9979 - val_loss: 0.0150 - val_mae: 0.0055 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01257\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0059 - mae: 0.0031 - accuracy: 0.9979 - val_loss: 0.0130 - val_mae: 0.0043 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01257\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0050 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0157 - val_mae: 0.0045 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01257\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0046 - mae: 0.0025 - accuracy: 0.9983 - val_loss: 0.0118 - val_mae: 0.0051 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01257 to 0.01185, saving model to model_7.h5\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0047 - mae: 0.0026 - accuracy: 0.9983 - val_loss: 0.0111 - val_mae: 0.0042 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01185 to 0.01115, saving model to model_7.h5\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0047 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0143 - val_mae: 0.0044 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01115\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0042 - mae: 0.0024 - accuracy: 0.9984 - val_loss: 0.0189 - val_mae: 0.0054 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01115\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0050 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0125 - val_mae: 0.0052 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01115\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0053 - mae: 0.0029 - accuracy: 0.9981 - val_loss: 0.0138 - val_mae: 0.0039 - val_accuracy: 0.9967\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01115\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0036 - mae: 0.0021 - accuracy: 0.9986 - val_loss: 0.0150 - val_mae: 0.0053 - val_accuracy: 0.9958\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01115\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0050 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0113 - val_mae: 0.0045 - val_accuracy: 0.9967\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01115\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0044 - mae: 0.0025 - accuracy: 0.9983 - val_loss: 0.0123 - val_mae: 0.0035 - val_accuracy: 0.9971\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01115\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0034 - mae: 0.0020 - accuracy: 0.9987 - val_loss: 0.0372 - val_mae: 0.0135 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01115\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0054 - mae: 0.0032 - accuracy: 0.9980 - val_loss: 0.0134 - val_mae: 0.0043 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01115\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0032 - mae: 0.0018 - accuracy: 0.9988 - val_loss: 0.0210 - val_mae: 0.0061 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01115\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0053 - mae: 0.0030 - accuracy: 0.9981 - val_loss: 0.0123 - val_mae: 0.0039 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01115\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0028 - mae: 0.0017 - accuracy: 0.9989 - val_loss: 0.0152 - val_mae: 0.0040 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01115\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0032 - mae: 0.0018 - accuracy: 0.9987 - val_loss: 0.0138 - val_mae: 0.0038 - val_accuracy: 0.9967\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01115\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0059 - mae: 0.0032 - accuracy: 0.9978 - val_loss: 0.0136 - val_mae: 0.0038 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01115\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0031 - mae: 0.0019 - accuracy: 0.9988 - val_loss: 0.0135 - val_mae: 0.0035 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01115\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0025 - mae: 0.0015 - accuracy: 0.9990 - val_loss: 0.0167 - val_mae: 0.0057 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01115\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0034 - mae: 0.0020 - accuracy: 0.9987 - val_loss: 0.0134 - val_mae: 0.0039 - val_accuracy: 0.9967\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01115\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0049 - mae: 0.0026 - accuracy: 0.9982 - val_loss: 0.0114 - val_mae: 0.0031 - val_accuracy: 0.9973\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01115\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0023 - mae: 0.0014 - accuracy: 0.9991 - val_loss: 0.0118 - val_mae: 0.0033 - val_accuracy: 0.9971\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01115\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0020 - mae: 0.0012 - accuracy: 0.9991 - val_loss: 0.0175 - val_mae: 0.0039 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01115\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0055 - mae: 0.0027 - accuracy: 0.9981 - val_loss: 0.0130 - val_mae: 0.0051 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01115\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0033 - mae: 0.0019 - accuracy: 0.9987 - val_loss: 0.0168 - val_mae: 0.0045 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01115\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0054 - mae: 0.0028 - accuracy: 0.9980 - val_loss: 0.0150 - val_mae: 0.0043 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01115\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0040 - mae: 0.0022 - accuracy: 0.9985 - val_loss: 0.0114 - val_mae: 0.0031 - val_accuracy: 0.9973\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01115\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0018 - mae: 0.0011 - accuracy: 0.9993 - val_loss: 0.0414 - val_mae: 0.0162 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01115\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0040 - mae: 0.0023 - accuracy: 0.9985 - val_loss: 0.0120 - val_mae: 0.0036 - val_accuracy: 0.9970\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01115\n",
      "Trainiere Modelle f√ºr Fireworks\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 13s 37ms/step - loss: 0.2740 - mae: 0.1940 - accuracy: 0.9037 - val_loss: 0.1469 - val_mae: 0.0649 - val_accuracy: 0.9646\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14689, saving model to model_8.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0853 - mae: 0.0435 - accuracy: 0.9726 - val_loss: 0.1112 - val_mae: 0.0371 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14689 to 0.11122, saving model to model_8.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0759 - mae: 0.0400 - accuracy: 0.9742 - val_loss: 0.0809 - val_mae: 0.0374 - val_accuracy: 0.9755\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11122 to 0.08093, saving model to model_8.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0669 - mae: 0.0354 - accuracy: 0.9776 - val_loss: 0.0778 - val_mae: 0.0436 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08093 to 0.07775, saving model to model_8.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0636 - mae: 0.0332 - accuracy: 0.9788 - val_loss: 0.0633 - val_mae: 0.0299 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07775 to 0.06329, saving model to model_8.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0579 - mae: 0.0310 - accuracy: 0.9801 - val_loss: 0.0696 - val_mae: 0.0293 - val_accuracy: 0.9782\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06329\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0545 - mae: 0.0289 - accuracy: 0.9813 - val_loss: 0.0707 - val_mae: 0.0274 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06329\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0519 - mae: 0.0274 - accuracy: 0.9822 - val_loss: 0.0539 - val_mae: 0.0263 - val_accuracy: 0.9820\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06329 to 0.05393, saving model to model_8.h5\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0471 - mae: 0.0253 - accuracy: 0.9840 - val_loss: 0.0557 - val_mae: 0.0282 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05393\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0462 - mae: 0.0245 - accuracy: 0.9842 - val_loss: 0.0579 - val_mae: 0.0295 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05393\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0435 - mae: 0.0239 - accuracy: 0.9852 - val_loss: 0.0731 - val_mae: 0.0380 - val_accuracy: 0.9735\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05393\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0400 - mae: 0.0219 - accuracy: 0.9862 - val_loss: 0.0575 - val_mae: 0.0258 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05393\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0387 - mae: 0.0207 - accuracy: 0.9867 - val_loss: 0.0543 - val_mae: 0.0228 - val_accuracy: 0.9834\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05393\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0407 - mae: 0.0221 - accuracy: 0.9858 - val_loss: 0.0623 - val_mae: 0.0235 - val_accuracy: 0.9809\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05393\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0383 - mae: 0.0207 - accuracy: 0.9865 - val_loss: 0.0643 - val_mae: 0.0243 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05393\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0350 - mae: 0.0190 - accuracy: 0.9879 - val_loss: 0.0849 - val_mae: 0.0429 - val_accuracy: 0.9675\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05393\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0311 - mae: 0.0169 - accuracy: 0.9892 - val_loss: 0.0700 - val_mae: 0.0326 - val_accuracy: 0.9752\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05393\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0312 - mae: 0.0170 - accuracy: 0.9891 - val_loss: 0.0708 - val_mae: 0.0207 - val_accuracy: 0.9822\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05393\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0310 - mae: 0.0169 - accuracy: 0.9890 - val_loss: 0.0555 - val_mae: 0.0209 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05393\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0279 - mae: 0.0154 - accuracy: 0.9899 - val_loss: 0.0768 - val_mae: 0.0227 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05393\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0261 - mae: 0.0142 - accuracy: 0.9907 - val_loss: 0.1121 - val_mae: 0.0454 - val_accuracy: 0.9605\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05393\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0273 - mae: 0.0152 - accuracy: 0.9901 - val_loss: 0.0725 - val_mae: 0.0220 - val_accuracy: 0.9810\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05393\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0252 - mae: 0.0138 - accuracy: 0.9910 - val_loss: 0.0595 - val_mae: 0.0222 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05393\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0223 - mae: 0.0125 - accuracy: 0.9920 - val_loss: 0.0794 - val_mae: 0.0315 - val_accuracy: 0.9738\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.05393\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0220 - mae: 0.0121 - accuracy: 0.9921 - val_loss: 0.0607 - val_mae: 0.0234 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05393\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0207 - mae: 0.0117 - accuracy: 0.9926 - val_loss: 0.0802 - val_mae: 0.0259 - val_accuracy: 0.9777\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05393\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0207 - mae: 0.0113 - accuracy: 0.9925 - val_loss: 0.0679 - val_mae: 0.0266 - val_accuracy: 0.9794\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05393\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0180 - mae: 0.0099 - accuracy: 0.9936 - val_loss: 0.1076 - val_mae: 0.0414 - val_accuracy: 0.9644\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05393\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0218 - mae: 0.0123 - accuracy: 0.9922 - val_loss: 0.0737 - val_mae: 0.0192 - val_accuracy: 0.9834\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05393\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0195 - mae: 0.0108 - accuracy: 0.9929 - val_loss: 0.0754 - val_mae: 0.0189 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05393\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0167 - mae: 0.0093 - accuracy: 0.9940 - val_loss: 0.1081 - val_mae: 0.0418 - val_accuracy: 0.9640\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05393\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0180 - mae: 0.0102 - accuracy: 0.9934 - val_loss: 0.0720 - val_mae: 0.0198 - val_accuracy: 0.9830\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05393\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0180 - mae: 0.0097 - accuracy: 0.9937 - val_loss: 0.0778 - val_mae: 0.0188 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05393\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0162 - mae: 0.0090 - accuracy: 0.9942 - val_loss: 0.0651 - val_mae: 0.0196 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05393\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0145 - mae: 0.0083 - accuracy: 0.9947 - val_loss: 0.0734 - val_mae: 0.0233 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05393\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0146 - mae: 0.0084 - accuracy: 0.9947 - val_loss: 0.0795 - val_mae: 0.0210 - val_accuracy: 0.9813\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05393\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0139 - mae: 0.0077 - accuracy: 0.9949 - val_loss: 0.0697 - val_mae: 0.0191 - val_accuracy: 0.9834\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05393\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0129 - mae: 0.0074 - accuracy: 0.9953 - val_loss: 0.0711 - val_mae: 0.0212 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05393\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0137 - mae: 0.0076 - accuracy: 0.9950 - val_loss: 0.0736 - val_mae: 0.0197 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05393\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0140 - mae: 0.0078 - accuracy: 0.9948 - val_loss: 0.0765 - val_mae: 0.0206 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05393\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0136 - mae: 0.0076 - accuracy: 0.9950 - val_loss: 0.0952 - val_mae: 0.0193 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05393\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0131 - mae: 0.0074 - accuracy: 0.9951 - val_loss: 0.0789 - val_mae: 0.0177 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05393\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0125 - mae: 0.0069 - accuracy: 0.9955 - val_loss: 0.0804 - val_mae: 0.0240 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05393\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0128 - mae: 0.0071 - accuracy: 0.9953 - val_loss: 0.0926 - val_mae: 0.0284 - val_accuracy: 0.9750\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05393\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0147 - mae: 0.0082 - accuracy: 0.9945 - val_loss: 0.0789 - val_mae: 0.0191 - val_accuracy: 0.9828\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05393\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0117 - mae: 0.0065 - accuracy: 0.9957 - val_loss: 0.0931 - val_mae: 0.0231 - val_accuracy: 0.9800\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05393\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0105 - mae: 0.0060 - accuracy: 0.9961 - val_loss: 0.0822 - val_mae: 0.0189 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05393\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0113 - mae: 0.0063 - accuracy: 0.9958 - val_loss: 0.0822 - val_mae: 0.0220 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05393\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0129 - mae: 0.0072 - accuracy: 0.9952 - val_loss: 0.0872 - val_mae: 0.0249 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05393\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0132 - mae: 0.0074 - accuracy: 0.9950 - val_loss: 0.0796 - val_mae: 0.0198 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05393\n",
      "Trainiere Modelle f√ºr Meow\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 12s 34ms/step - loss: 0.2896 - mae: 0.2045 - accuracy: 0.8889 - val_loss: 0.1618 - val_mae: 0.0587 - val_accuracy: 0.9617\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16175, saving model to model_9.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0872 - mae: 0.0463 - accuracy: 0.9715 - val_loss: 0.0928 - val_mae: 0.0483 - val_accuracy: 0.9696\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16175 to 0.09276, saving model to model_9.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0683 - mae: 0.0363 - accuracy: 0.9771 - val_loss: 0.1042 - val_mae: 0.0644 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09276\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0583 - mae: 0.0313 - accuracy: 0.9805 - val_loss: 0.0657 - val_mae: 0.0351 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09276 to 0.06572, saving model to model_9.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0541 - mae: 0.0283 - accuracy: 0.9820 - val_loss: 0.0692 - val_mae: 0.0402 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06572\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0508 - mae: 0.0267 - accuracy: 0.9832 - val_loss: 0.0657 - val_mae: 0.0261 - val_accuracy: 0.9791\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06572\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0470 - mae: 0.0245 - accuracy: 0.9844 - val_loss: 0.0512 - val_mae: 0.0267 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06572 to 0.05118, saving model to model_9.h5\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0434 - mae: 0.0224 - accuracy: 0.9860 - val_loss: 0.0771 - val_mae: 0.0385 - val_accuracy: 0.9727\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05118\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0416 - mae: 0.0214 - accuracy: 0.9862 - val_loss: 0.0515 - val_mae: 0.0229 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05118\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0365 - mae: 0.0188 - accuracy: 0.9881 - val_loss: 0.0580 - val_mae: 0.0213 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05118\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0351 - mae: 0.0182 - accuracy: 0.9886 - val_loss: 0.0476 - val_mae: 0.0211 - val_accuracy: 0.9853\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05118 to 0.04763, saving model to model_9.h5\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0350 - mae: 0.0182 - accuracy: 0.9886 - val_loss: 0.0452 - val_mae: 0.0239 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04763 to 0.04524, saving model to model_9.h5\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0321 - mae: 0.0164 - accuracy: 0.9897 - val_loss: 0.0457 - val_mae: 0.0210 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04524\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0284 - mae: 0.0146 - accuracy: 0.9909 - val_loss: 0.0459 - val_mae: 0.0176 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04524\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0285 - mae: 0.0146 - accuracy: 0.9908 - val_loss: 0.0447 - val_mae: 0.0183 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.04524 to 0.04474, saving model to model_9.h5\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0261 - mae: 0.0135 - accuracy: 0.9914 - val_loss: 0.0461 - val_mae: 0.0197 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04474\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0258 - mae: 0.0132 - accuracy: 0.9916 - val_loss: 0.0472 - val_mae: 0.0225 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04474\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0268 - mae: 0.0138 - accuracy: 0.9914 - val_loss: 0.0445 - val_mae: 0.0193 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04474 to 0.04452, saving model to model_9.h5\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0241 - mae: 0.0125 - accuracy: 0.9920 - val_loss: 0.0468 - val_mae: 0.0205 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04452\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0225 - mae: 0.0116 - accuracy: 0.9927 - val_loss: 0.0464 - val_mae: 0.0160 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04452\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0213 - mae: 0.0112 - accuracy: 0.9930 - val_loss: 0.0452 - val_mae: 0.0181 - val_accuracy: 0.9867\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04452\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0189 - mae: 0.0099 - accuracy: 0.9937 - val_loss: 0.0479 - val_mae: 0.0163 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04452\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 8s 34ms/step - loss: 0.0199 - mae: 0.0105 - accuracy: 0.9933 - val_loss: 0.0454 - val_mae: 0.0175 - val_accuracy: 0.9871\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04452\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0203 - mae: 0.0107 - accuracy: 0.9933 - val_loss: 0.0520 - val_mae: 0.0231 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04452\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0176 - mae: 0.0093 - accuracy: 0.9942 - val_loss: 0.0470 - val_mae: 0.0157 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04452\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0170 - mae: 0.0090 - accuracy: 0.9943 - val_loss: 0.0493 - val_mae: 0.0234 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04452\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0183 - mae: 0.0096 - accuracy: 0.9939 - val_loss: 0.0564 - val_mae: 0.0151 - val_accuracy: 0.9868\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04452\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0152 - mae: 0.0081 - accuracy: 0.9948 - val_loss: 0.0562 - val_mae: 0.0155 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04452\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0154 - mae: 0.0082 - accuracy: 0.9947 - val_loss: 0.0538 - val_mae: 0.0179 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04452\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0162 - mae: 0.0087 - accuracy: 0.9946 - val_loss: 0.0500 - val_mae: 0.0151 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04452\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0156 - mae: 0.0084 - accuracy: 0.9947 - val_loss: 0.0545 - val_mae: 0.0154 - val_accuracy: 0.9872\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04452\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0136 - mae: 0.0072 - accuracy: 0.9953 - val_loss: 0.0883 - val_mae: 0.0337 - val_accuracy: 0.9714\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04452\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0142 - mae: 0.0076 - accuracy: 0.9951 - val_loss: 0.0516 - val_mae: 0.0158 - val_accuracy: 0.9865\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04452\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0133 - mae: 0.0070 - accuracy: 0.9955 - val_loss: 0.0483 - val_mae: 0.0162 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04452\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 8s 33ms/step - loss: 0.0153 - mae: 0.0081 - accuracy: 0.9948 - val_loss: 0.0461 - val_mae: 0.0161 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04452\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0125 - mae: 0.0067 - accuracy: 0.9957 - val_loss: 0.0490 - val_mae: 0.0188 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04452\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0121 - mae: 0.0066 - accuracy: 0.9958 - val_loss: 0.0569 - val_mae: 0.0144 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04452\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0116 - mae: 0.0062 - accuracy: 0.9960 - val_loss: 0.0624 - val_mae: 0.0257 - val_accuracy: 0.9799\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04452\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 8s 32ms/step - loss: 0.0131 - mae: 0.0072 - accuracy: 0.9954 - val_loss: 0.0557 - val_mae: 0.0169 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04452\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0099 - mae: 0.0053 - accuracy: 0.9966 - val_loss: 0.0520 - val_mae: 0.0166 - val_accuracy: 0.9863\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04452\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 37ms/step - loss: 0.0112 - mae: 0.0060 - accuracy: 0.9962 - val_loss: 0.0532 - val_mae: 0.0158 - val_accuracy: 0.9866\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04452\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0116 - mae: 0.0062 - accuracy: 0.9960 - val_loss: 0.0570 - val_mae: 0.0148 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04452\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0106 - mae: 0.0058 - accuracy: 0.9963 - val_loss: 0.0577 - val_mae: 0.0145 - val_accuracy: 0.9872\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04452\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0100 - mae: 0.0054 - accuracy: 0.9965 - val_loss: 0.0548 - val_mae: 0.0196 - val_accuracy: 0.9847\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04452\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0102 - mae: 0.0057 - accuracy: 0.9964 - val_loss: 0.0559 - val_mae: 0.0171 - val_accuracy: 0.9854\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04452\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0089 - mae: 0.0049 - accuracy: 0.9969 - val_loss: 0.0612 - val_mae: 0.0209 - val_accuracy: 0.9826\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04452\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0107 - mae: 0.0058 - accuracy: 0.9961 - val_loss: 0.0516 - val_mae: 0.0149 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04452\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0098 - mae: 0.0053 - accuracy: 0.9966 - val_loss: 0.0578 - val_mae: 0.0162 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04452\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0091 - mae: 0.0050 - accuracy: 0.9967 - val_loss: 0.0644 - val_mae: 0.0217 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04452\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0095 - mae: 0.0053 - accuracy: 0.9965 - val_loss: 0.0712 - val_mae: 0.0247 - val_accuracy: 0.9803\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04452\n",
      "Trainiere Modelle f√ºr Scratching_(performance_technique)\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 13s 37ms/step - loss: 0.2696 - mae: 0.2006 - accuracy: 0.9227 - val_loss: 0.1440 - val_mae: 0.0518 - val_accuracy: 0.9651\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14404, saving model to model_10.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0414 - mae: 0.0220 - accuracy: 0.9867 - val_loss: 0.1798 - val_mae: 0.0340 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.14404\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0303 - mae: 0.0160 - accuracy: 0.9901 - val_loss: 0.0312 - val_mae: 0.0131 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14404 to 0.03121, saving model to model_10.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0249 - mae: 0.0128 - accuracy: 0.9919 - val_loss: 0.0443 - val_mae: 0.0226 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03121\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0215 - mae: 0.0111 - accuracy: 0.9931 - val_loss: 0.0244 - val_mae: 0.0142 - val_accuracy: 0.9916\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03121 to 0.02440, saving model to model_10.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0174 - mae: 0.0094 - accuracy: 0.9941 - val_loss: 0.0191 - val_mae: 0.0103 - val_accuracy: 0.9937\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02440 to 0.01905, saving model to model_10.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0173 - mae: 0.0092 - accuracy: 0.9942 - val_loss: 0.0185 - val_mae: 0.0086 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01905 to 0.01848, saving model to model_10.h5\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0157 - mae: 0.0083 - accuracy: 0.9947 - val_loss: 0.0178 - val_mae: 0.0093 - val_accuracy: 0.9937\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01848 to 0.01782, saving model to model_10.h5\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0164 - mae: 0.0087 - accuracy: 0.9946 - val_loss: 0.0318 - val_mae: 0.0190 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01782\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0143 - mae: 0.0076 - accuracy: 0.9951 - val_loss: 0.0168 - val_mae: 0.0085 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01782 to 0.01676, saving model to model_10.h5\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0122 - mae: 0.0065 - accuracy: 0.9958 - val_loss: 0.0149 - val_mae: 0.0062 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01676 to 0.01489, saving model to model_10.h5\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0112 - mae: 0.0058 - accuracy: 0.9962 - val_loss: 0.0189 - val_mae: 0.0102 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01489\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0110 - mae: 0.0059 - accuracy: 0.9963 - val_loss: 0.0140 - val_mae: 0.0064 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01489 to 0.01402, saving model to model_10.h5\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0104 - mae: 0.0055 - accuracy: 0.9963 - val_loss: 0.0139 - val_mae: 0.0071 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01402 to 0.01393, saving model to model_10.h5\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0092 - mae: 0.0051 - accuracy: 0.9968 - val_loss: 0.0211 - val_mae: 0.0103 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01393\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0091 - mae: 0.0051 - accuracy: 0.9967 - val_loss: 0.0123 - val_mae: 0.0056 - val_accuracy: 0.9959\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01393 to 0.01225, saving model to model_10.h5\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0090 - mae: 0.0048 - accuracy: 0.9968 - val_loss: 0.0126 - val_mae: 0.0061 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01225\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0077 - mae: 0.0043 - accuracy: 0.9972 - val_loss: 0.0174 - val_mae: 0.0062 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01225\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0081 - mae: 0.0045 - accuracy: 0.9970 - val_loss: 0.1723 - val_mae: 0.0660 - val_accuracy: 0.9418\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01225\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0095 - mae: 0.0054 - accuracy: 0.9966 - val_loss: 0.0152 - val_mae: 0.0060 - val_accuracy: 0.9956\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01225\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0074 - mae: 0.0041 - accuracy: 0.9974 - val_loss: 0.0153 - val_mae: 0.0076 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01225\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0078 - mae: 0.0043 - accuracy: 0.9972 - val_loss: 0.0133 - val_mae: 0.0055 - val_accuracy: 0.9958\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01225\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0079 - mae: 0.0044 - accuracy: 0.9971 - val_loss: 0.0282 - val_mae: 0.0107 - val_accuracy: 0.9909\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01225\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0090 - mae: 0.0049 - accuracy: 0.9967 - val_loss: 0.0114 - val_mae: 0.0047 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01225 to 0.01145, saving model to model_10.h5\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0069 - mae: 0.0038 - accuracy: 0.9974 - val_loss: 0.0259 - val_mae: 0.0110 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01145\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0063 - mae: 0.0036 - accuracy: 0.9976 - val_loss: 0.0154 - val_mae: 0.0055 - val_accuracy: 0.9956\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01145\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0061 - mae: 0.0034 - accuracy: 0.9977 - val_loss: 0.0153 - val_mae: 0.0050 - val_accuracy: 0.9958\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01145\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0065 - mae: 0.0037 - accuracy: 0.9975 - val_loss: 0.0341 - val_mae: 0.0145 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01145\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0069 - mae: 0.0039 - accuracy: 0.9974 - val_loss: 0.0149 - val_mae: 0.0066 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01145\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 36ms/step - loss: 0.0053 - mae: 0.0031 - accuracy: 0.9979 - val_loss: 0.0221 - val_mae: 0.0091 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01145\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0054 - mae: 0.0032 - accuracy: 0.9979 - val_loss: 0.0197 - val_mae: 0.0088 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01145\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0070 - mae: 0.0038 - accuracy: 0.9975 - val_loss: 0.0191 - val_mae: 0.0059 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01145\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0055 - mae: 0.0032 - accuracy: 0.9979 - val_loss: 0.0142 - val_mae: 0.0056 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01145\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0048 - mae: 0.0027 - accuracy: 0.9982 - val_loss: 0.0209 - val_mae: 0.0056 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01145\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0063 - mae: 0.0035 - accuracy: 0.9976 - val_loss: 0.0174 - val_mae: 0.0071 - val_accuracy: 0.9942\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01145\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0062 - mae: 0.0036 - accuracy: 0.9976 - val_loss: 0.0134 - val_mae: 0.0049 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01145\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0052 - mae: 0.0030 - accuracy: 0.9980 - val_loss: 0.0172 - val_mae: 0.0073 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01145\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0052 - mae: 0.0031 - accuracy: 0.9980 - val_loss: 0.0130 - val_mae: 0.0049 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01145\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0056 - mae: 0.0032 - accuracy: 0.9978 - val_loss: 0.0140 - val_mae: 0.0050 - val_accuracy: 0.9959\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01145\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0041 - mae: 0.0024 - accuracy: 0.9983 - val_loss: 0.0816 - val_mae: 0.0255 - val_accuracy: 0.9772\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01145\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0081 - mae: 0.0043 - accuracy: 0.9970 - val_loss: 0.0141 - val_mae: 0.0052 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01145\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0048 - mae: 0.0029 - accuracy: 0.9981 - val_loss: 0.0122 - val_mae: 0.0048 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01145\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0036 - mae: 0.0022 - accuracy: 0.9986 - val_loss: 0.0142 - val_mae: 0.0045 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01145\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0040 - mae: 0.0023 - accuracy: 0.9984 - val_loss: 0.0146 - val_mae: 0.0048 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01145\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0043 - mae: 0.0025 - accuracy: 0.9984 - val_loss: 0.0149 - val_mae: 0.0052 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01145\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0049 - mae: 0.0028 - accuracy: 0.9981 - val_loss: 0.0169 - val_mae: 0.0067 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01145\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0042 - mae: 0.0025 - accuracy: 0.9983 - val_loss: 0.0193 - val_mae: 0.0068 - val_accuracy: 0.9942\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01145\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0040 - mae: 0.0024 - accuracy: 0.9984 - val_loss: 0.0338 - val_mae: 0.0145 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01145\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0049 - mae: 0.0029 - accuracy: 0.9982 - val_loss: 0.0148 - val_mae: 0.0056 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01145\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0037 - mae: 0.0022 - accuracy: 0.9985 - val_loss: 0.0219 - val_mae: 0.0059 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01145\n",
      "Trainiere Modelle f√ºr Shatter\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 13s 37ms/step - loss: 0.1905 - mae: 0.1407 - accuracy: 0.9623 - val_loss: 0.1365 - val_mae: 0.0740 - val_accuracy: 0.9646\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13654, saving model to model_11.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0652 - mae: 0.0349 - accuracy: 0.9783 - val_loss: 0.0729 - val_mae: 0.0334 - val_accuracy: 0.9734\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13654 to 0.07292, saving model to model_11.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0509 - mae: 0.0265 - accuracy: 0.9833 - val_loss: 0.0483 - val_mae: 0.0264 - val_accuracy: 0.9846\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07292 to 0.04831, saving model to model_11.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0444 - mae: 0.0234 - accuracy: 0.9856 - val_loss: 0.0477 - val_mae: 0.0273 - val_accuracy: 0.9840\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04831 to 0.04773, saving model to model_11.h5\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0402 - mae: 0.0211 - accuracy: 0.9866 - val_loss: 0.0385 - val_mae: 0.0188 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04773 to 0.03851, saving model to model_11.h5\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0370 - mae: 0.0190 - accuracy: 0.9881 - val_loss: 0.0503 - val_mae: 0.0178 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03851\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0328 - mae: 0.0170 - accuracy: 0.9893 - val_loss: 0.0401 - val_mae: 0.0174 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03851\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0309 - mae: 0.0157 - accuracy: 0.9902 - val_loss: 0.0422 - val_mae: 0.0172 - val_accuracy: 0.9880\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03851\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0276 - mae: 0.0141 - accuracy: 0.9912 - val_loss: 0.0380 - val_mae: 0.0135 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03851 to 0.03805, saving model to model_11.h5\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0255 - mae: 0.0130 - accuracy: 0.9918 - val_loss: 0.0408 - val_mae: 0.0163 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03805\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0257 - mae: 0.0133 - accuracy: 0.9917 - val_loss: 0.0441 - val_mae: 0.0201 - val_accuracy: 0.9853\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.03805\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0213 - mae: 0.0110 - accuracy: 0.9931 - val_loss: 0.0374 - val_mae: 0.0160 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03805 to 0.03738, saving model to model_11.h5\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0219 - mae: 0.0115 - accuracy: 0.9928 - val_loss: 0.0362 - val_mae: 0.0170 - val_accuracy: 0.9880\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03738 to 0.03622, saving model to model_11.h5\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0210 - mae: 0.0111 - accuracy: 0.9931 - val_loss: 0.0389 - val_mae: 0.0147 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03622\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0207 - mae: 0.0106 - accuracy: 0.9935 - val_loss: 0.0409 - val_mae: 0.0138 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03622\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0183 - mae: 0.0096 - accuracy: 0.9940 - val_loss: 0.0472 - val_mae: 0.0151 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03622\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0175 - mae: 0.0091 - accuracy: 0.9942 - val_loss: 0.0561 - val_mae: 0.0147 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.03622\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0182 - mae: 0.0097 - accuracy: 0.9938 - val_loss: 0.0401 - val_mae: 0.0164 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.03622\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0157 - mae: 0.0084 - accuracy: 0.9948 - val_loss: 0.0429 - val_mae: 0.0114 - val_accuracy: 0.9904\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.03622\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0160 - mae: 0.0084 - accuracy: 0.9946 - val_loss: 0.0353 - val_mae: 0.0121 - val_accuracy: 0.9901\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.03622 to 0.03533, saving model to model_11.h5\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0141 - mae: 0.0074 - accuracy: 0.9952 - val_loss: 0.0391 - val_mae: 0.0127 - val_accuracy: 0.9897\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.03533\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0148 - mae: 0.0078 - accuracy: 0.9949 - val_loss: 0.0421 - val_mae: 0.0144 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.03533\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0130 - mae: 0.0070 - accuracy: 0.9955 - val_loss: 0.0354 - val_mae: 0.0118 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03533\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0134 - mae: 0.0071 - accuracy: 0.9955 - val_loss: 0.0412 - val_mae: 0.0122 - val_accuracy: 0.9901\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03533\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0130 - mae: 0.0069 - accuracy: 0.9955 - val_loss: 0.0431 - val_mae: 0.0117 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03533\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0123 - mae: 0.0066 - accuracy: 0.9958 - val_loss: 0.0408 - val_mae: 0.0153 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03533\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0113 - mae: 0.0061 - accuracy: 0.9961 - val_loss: 0.0473 - val_mae: 0.0184 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03533\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0131 - mae: 0.0068 - accuracy: 0.9955 - val_loss: 0.0623 - val_mae: 0.0127 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03533\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0120 - mae: 0.0066 - accuracy: 0.9959 - val_loss: 0.0561 - val_mae: 0.0192 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03533\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0120 - mae: 0.0064 - accuracy: 0.9958 - val_loss: 0.0450 - val_mae: 0.0111 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03533\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0094 - mae: 0.0052 - accuracy: 0.9967 - val_loss: 0.0445 - val_mae: 0.0113 - val_accuracy: 0.9902\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.03533\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0100 - mae: 0.0054 - accuracy: 0.9965 - val_loss: 0.0441 - val_mae: 0.0124 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03533\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0103 - mae: 0.0057 - accuracy: 0.9963 - val_loss: 0.0405 - val_mae: 0.0122 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03533\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0094 - mae: 0.0050 - accuracy: 0.9966 - val_loss: 0.0398 - val_mae: 0.0111 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03533\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0092 - mae: 0.0051 - accuracy: 0.9967 - val_loss: 0.0491 - val_mae: 0.0113 - val_accuracy: 0.9898\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03533\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0104 - mae: 0.0057 - accuracy: 0.9963 - val_loss: 0.0427 - val_mae: 0.0123 - val_accuracy: 0.9892\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03533\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0083 - mae: 0.0045 - accuracy: 0.9970 - val_loss: 0.0433 - val_mae: 0.0107 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03533\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0075 - mae: 0.0043 - accuracy: 0.9973 - val_loss: 0.0492 - val_mae: 0.0170 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03533\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0072 - mae: 0.0040 - accuracy: 0.9974 - val_loss: 0.0451 - val_mae: 0.0149 - val_accuracy: 0.9876\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03533\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0097 - mae: 0.0053 - accuracy: 0.9965 - val_loss: 0.0394 - val_mae: 0.0104 - val_accuracy: 0.9911\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03533\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0093 - mae: 0.0049 - accuracy: 0.9968 - val_loss: 0.0401 - val_mae: 0.0112 - val_accuracy: 0.9905\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03533\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0098 - mae: 0.0053 - accuracy: 0.9965 - val_loss: 0.0437 - val_mae: 0.0149 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03533\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0067 - mae: 0.0038 - accuracy: 0.9975 - val_loss: 0.0539 - val_mae: 0.0119 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03533\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0075 - mae: 0.0042 - accuracy: 0.9972 - val_loss: 0.0604 - val_mae: 0.0229 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03533\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0091 - mae: 0.0050 - accuracy: 0.9968 - val_loss: 0.0380 - val_mae: 0.0108 - val_accuracy: 0.9908\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03533\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0075 - mae: 0.0041 - accuracy: 0.9972 - val_loss: 0.0387 - val_mae: 0.0110 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03533\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0063 - mae: 0.0035 - accuracy: 0.9977 - val_loss: 0.0441 - val_mae: 0.0104 - val_accuracy: 0.9912\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03533\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0058 - mae: 0.0033 - accuracy: 0.9979 - val_loss: 0.0464 - val_mae: 0.0097 - val_accuracy: 0.9911\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03533\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0062 - mae: 0.0035 - accuracy: 0.9977 - val_loss: 0.0427 - val_mae: 0.0112 - val_accuracy: 0.9904\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03533\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0076 - mae: 0.0042 - accuracy: 0.9972 - val_loss: 0.0488 - val_mae: 0.0131 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03533\n",
      "Trainiere Modelle f√ºr Shout\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 13s 37ms/step - loss: 0.2443 - mae: 0.1783 - accuracy: 0.9517 - val_loss: 0.1396 - val_mae: 0.0612 - val_accuracy: 0.9678\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13963, saving model to model_12.h5\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0726 - mae: 0.0407 - accuracy: 0.9733 - val_loss: 0.0808 - val_mae: 0.0336 - val_accuracy: 0.9700\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13963 to 0.08080, saving model to model_12.h5\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0600 - mae: 0.0331 - accuracy: 0.9785 - val_loss: 0.0522 - val_mae: 0.0262 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08080 to 0.05217, saving model to model_12.h5\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0551 - mae: 0.0303 - accuracy: 0.9802 - val_loss: 0.0575 - val_mae: 0.0323 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05217\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0490 - mae: 0.0260 - accuracy: 0.9831 - val_loss: 0.0749 - val_mae: 0.0425 - val_accuracy: 0.9713\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05217\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0432 - mae: 0.0238 - accuracy: 0.9848 - val_loss: 0.0439 - val_mae: 0.0249 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05217 to 0.04394, saving model to model_12.h5\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0411 - mae: 0.0225 - accuracy: 0.9855 - val_loss: 0.0436 - val_mae: 0.0186 - val_accuracy: 0.9860\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04394 to 0.04357, saving model to model_12.h5\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0352 - mae: 0.0186 - accuracy: 0.9880 - val_loss: 0.0453 - val_mae: 0.0238 - val_accuracy: 0.9842\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04357\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0334 - mae: 0.0181 - accuracy: 0.9887 - val_loss: 0.0529 - val_mae: 0.0289 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04357\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0303 - mae: 0.0164 - accuracy: 0.9892 - val_loss: 0.0442 - val_mae: 0.0240 - val_accuracy: 0.9851\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04357\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0277 - mae: 0.0152 - accuracy: 0.9903 - val_loss: 0.0503 - val_mae: 0.0257 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04357\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0261 - mae: 0.0139 - accuracy: 0.9909 - val_loss: 0.0390 - val_mae: 0.0181 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04357 to 0.03896, saving model to model_12.h5\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0258 - mae: 0.0139 - accuracy: 0.9911 - val_loss: 0.0573 - val_mae: 0.0299 - val_accuracy: 0.9801\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03896\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0226 - mae: 0.0125 - accuracy: 0.9922 - val_loss: 0.0434 - val_mae: 0.0141 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03896\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0215 - mae: 0.0117 - accuracy: 0.9925 - val_loss: 0.0442 - val_mae: 0.0204 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03896\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0202 - mae: 0.0109 - accuracy: 0.9930 - val_loss: 0.0389 - val_mae: 0.0139 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03896 to 0.03887, saving model to model_12.h5\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0202 - mae: 0.0111 - accuracy: 0.9927 - val_loss: 0.0450 - val_mae: 0.0159 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.03887\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0182 - mae: 0.0100 - accuracy: 0.9936 - val_loss: 0.0573 - val_mae: 0.0252 - val_accuracy: 0.9805\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.03887\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0164 - mae: 0.0089 - accuracy: 0.9942 - val_loss: 0.0388 - val_mae: 0.0162 - val_accuracy: 0.9879\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.03887 to 0.03876, saving model to model_12.h5\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0170 - mae: 0.0094 - accuracy: 0.9940 - val_loss: 0.0432 - val_mae: 0.0147 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.03876\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0158 - mae: 0.0087 - accuracy: 0.9943 - val_loss: 0.0374 - val_mae: 0.0133 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.03876 to 0.03744, saving model to model_12.h5\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0136 - mae: 0.0073 - accuracy: 0.9952 - val_loss: 0.0490 - val_mae: 0.0200 - val_accuracy: 0.9842\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.03744\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0143 - mae: 0.0078 - accuracy: 0.9949 - val_loss: 0.0385 - val_mae: 0.0141 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03744\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0123 - mae: 0.0069 - accuracy: 0.9957 - val_loss: 0.0397 - val_mae: 0.0142 - val_accuracy: 0.9885\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03744\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0119 - mae: 0.0064 - accuracy: 0.9958 - val_loss: 0.0429 - val_mae: 0.0127 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03744\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0118 - mae: 0.0064 - accuracy: 0.9959 - val_loss: 0.0426 - val_mae: 0.0153 - val_accuracy: 0.9882\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03744\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0107 - mae: 0.0058 - accuracy: 0.9962 - val_loss: 0.0427 - val_mae: 0.0127 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03744\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0104 - mae: 0.0057 - accuracy: 0.9964 - val_loss: 0.0525 - val_mae: 0.0137 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03744\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0116 - mae: 0.0064 - accuracy: 0.9959 - val_loss: 0.0463 - val_mae: 0.0129 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03744\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0102 - mae: 0.0056 - accuracy: 0.9964 - val_loss: 0.0598 - val_mae: 0.0248 - val_accuracy: 0.9802\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03744\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0108 - mae: 0.0060 - accuracy: 0.9961 - val_loss: 0.0407 - val_mae: 0.0130 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.03744\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0093 - mae: 0.0053 - accuracy: 0.9967 - val_loss: 0.0501 - val_mae: 0.0121 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03744\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0104 - mae: 0.0056 - accuracy: 0.9963 - val_loss: 0.0531 - val_mae: 0.0166 - val_accuracy: 0.9858\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03744\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0108 - mae: 0.0059 - accuracy: 0.9961 - val_loss: 0.0477 - val_mae: 0.0144 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.03744\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0098 - mae: 0.0054 - accuracy: 0.9966 - val_loss: 0.0464 - val_mae: 0.0124 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03744\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0089 - mae: 0.0048 - accuracy: 0.9968 - val_loss: 0.0434 - val_mae: 0.0118 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03744\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0088 - mae: 0.0049 - accuracy: 0.9969 - val_loss: 0.0435 - val_mae: 0.0123 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03744\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0080 - mae: 0.0044 - accuracy: 0.9971 - val_loss: 0.0533 - val_mae: 0.0172 - val_accuracy: 0.9855\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03744\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0084 - mae: 0.0046 - accuracy: 0.9970 - val_loss: 0.0529 - val_mae: 0.0129 - val_accuracy: 0.9886\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03744\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0082 - mae: 0.0045 - accuracy: 0.9971 - val_loss: 0.0445 - val_mae: 0.0128 - val_accuracy: 0.9890\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.03744\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0086 - mae: 0.0047 - accuracy: 0.9969 - val_loss: 0.0473 - val_mae: 0.0134 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.03744\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0083 - mae: 0.0045 - accuracy: 0.9970 - val_loss: 0.0463 - val_mae: 0.0131 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.03744\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0094 - mae: 0.0051 - accuracy: 0.9966 - val_loss: 0.0420 - val_mae: 0.0116 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.03744\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0078 - mae: 0.0044 - accuracy: 0.9972 - val_loss: 0.0412 - val_mae: 0.0129 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.03744\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0085 - mae: 0.0047 - accuracy: 0.9969 - val_loss: 0.0488 - val_mae: 0.0118 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.03744\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0072 - mae: 0.0041 - accuracy: 0.9973 - val_loss: 0.0432 - val_mae: 0.0114 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.03744\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0069 - mae: 0.0039 - accuracy: 0.9974 - val_loss: 0.0568 - val_mae: 0.0153 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.03744\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0070 - mae: 0.0040 - accuracy: 0.9974 - val_loss: 0.0493 - val_mae: 0.0114 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.03744\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0062 - mae: 0.0034 - accuracy: 0.9978 - val_loss: 0.0575 - val_mae: 0.0174 - val_accuracy: 0.9852\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.03744\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 9s 35ms/step - loss: 0.0067 - mae: 0.0038 - accuracy: 0.9976 - val_loss: 0.0468 - val_mae: 0.0117 - val_accuracy: 0.9895\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.03744\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for classNumber in range(numClasses):\n",
    "    print(\"Trainiere Modell f√ºr \"+bbdc.invLabelMap[classNumber])\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint('model_'+str(classNumber)+'.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    modelsForSingleClasses[classNumber].compile(optimizer=opt, loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "    histories.append(modelsForSingleClasses[classNumber].fit(X_train,Y_train_classes[classNumber], batch_size=32, epochs=50, validation_data=(X_validation, Y_validation_classes[classNumber]), shuffle=True, callbacks=[checkpoint]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "crazy-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numClasses):\n",
    "    modelsForSingleClasses[i].save(\"ForestLastEpoch/model\"+str(i)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cubic-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [classModel(input_layer) for classModel in modelsForSingleClasses]\n",
    "outputs = [layers.Lambda(lambda x: x[:,:,:1])(o) for o in outputs]\n",
    "\n",
    "x = layers.Concatenate(axis=2)(outputs)\n",
    "x = layers.Conv1D(numClasses, kernel_size=3, padding='same')(x)\n",
    "x = layers.Conv1D(numClasses, kernel_size=1, activation='softmax')(x)\n",
    "\n",
    "majorityVoteModel = tf.keras.models.Model(inputs=input_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "inappropriate-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 115s 347ms/step - loss: 1.7748 - mae: 0.1188 - accuracy: 0.6088 - val_loss: 0.5159 - val_mae: 0.0432 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51586, saving model to majorityVoteModel.h5\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 83s 331ms/step - loss: 0.2181 - mae: 0.0248 - accuracy: 0.9773 - val_loss: 0.3643 - val_mae: 0.0208 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51586 to 0.36429, saving model to majorityVoteModel.h5\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 89s 355ms/step - loss: 0.0924 - mae: 0.0088 - accuracy: 0.9810 - val_loss: 0.3609 - val_mae: 0.0173 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36429 to 0.36090, saving model to majorityVoteModel.h5\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 82s 326ms/step - loss: 0.0734 - mae: 0.0060 - accuracy: 0.9815 - val_loss: 0.3656 - val_mae: 0.0161 - val_accuracy: 0.9156\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.36090\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 85s 340ms/step - loss: 0.0687 - mae: 0.0051 - accuracy: 0.9814 - val_loss: 0.3699 - val_mae: 0.0155 - val_accuracy: 0.9156\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.36090\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 85s 341ms/step - loss: 0.0650 - mae: 0.0046 - accuracy: 0.9816 - val_loss: 0.3729 - val_mae: 0.0152 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36090\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 72s 288ms/step - loss: 0.0625 - mae: 0.0043 - accuracy: 0.9819 - val_loss: 0.3750 - val_mae: 0.0150 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36090\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 71s 283ms/step - loss: 0.0627 - mae: 0.0042 - accuracy: 0.9817 - val_loss: 0.3767 - val_mae: 0.0148 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36090\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 71s 282ms/step - loss: 0.0619 - mae: 0.0041 - accuracy: 0.9816 - val_loss: 0.3776 - val_mae: 0.0147 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36090\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 73s 291ms/step - loss: 0.0597 - mae: 0.0040 - accuracy: 0.9821 - val_loss: 0.3786 - val_mae: 0.0147 - val_accuracy: 0.9156\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36090\n"
     ]
    }
   ],
   "source": [
    "#Mit crossentropy\n",
    "#checkpoint = ModelCheckpoint('model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('majorityVoteModel.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "majorityVoteModel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "history = majorityVoteModel.fit(X_train,Y_train, batch_size=32, epochs=10, validation_data=(X_validation, Y_validation), shuffle=True, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "announced-making",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for mae\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('model mae')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "configured-means",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fallen-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "confirmed-exploration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 8s 239ms/step - loss: 0.3659 - mae: 0.0143 - accuracy: 0.9177\n"
     ]
    }
   ],
   "source": [
    "scores = majorityVoteModel.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-belfast",
   "metadata": {},
   "source": [
    "# Prediction der Challenge-Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "whole-viewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:41, 71.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_challenge, _, timepoints, challengeFileList = bbdc.load_data(\"challenge_filelist_dummy.csv\", pathToDataset+\"eval/\")\n",
    "inputShape = X_challenge[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "challengePrediction = majorityVoteModel.predict(X_challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cooked-austria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jannes/Programme/miniconda3/envs/gpuclone/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jannes/Programme/miniconda3/envs/gpuclone/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "df = bbdc.getPredictionAsSequenceDF(challengePrediction, timepoints, challengeFileList, calculateProbs=True)\n",
    "df.to_csv(\"../predictions/jannes/majorityVoteUNet_challenge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "immune-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "fs = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "funny-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11233_mix.wav\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1232\n",
    "print(challengeFileList[index])\n",
    "plt.figure(figsize=(25,5))\n",
    "# read audio samples\n",
    "input_data = read(\"../data/final_pre_dataset/eval/\"+challengeFileList[index])\n",
    "audio = input_data[1]\n",
    "time=np.linspace(0, len(audio)/fs, num=len(audio))\n",
    "plt.plot(time,audio)\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Sample Wav\")\n",
    "\n",
    "groups = bbdc.groupSequences(challengePrediction[index], timepoints)\n",
    "for group in groups:\n",
    "    if group[0][0]==0:\n",
    "        onset = group[0][1]\n",
    "        offset = group[-1][1]\n",
    "        plt.axvspan(onset, offset, alpha=0.7, color='black', ymin=0, ymax=1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
